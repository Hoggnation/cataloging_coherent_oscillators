{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23fb83cc-b68b-4fd6-be5f-3c6b792c3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import scipy.signal\n",
    "from astropy import units as u\n",
    "from scipy.interpolate import CubicSpline\n",
    "from math import cos, sin, radians\n",
    "#from astropy.table import Table\n",
    "#from astropy.io import ascii\n",
    "import nana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dc21ef-499e-4525-9b3b-09df65a69b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_started(num_of_peaks, xs, ys): \n",
    "    \"\"\"\n",
    "    \n",
    "    Identifies and returns the indices of the highest peaks in a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        num_of_peaks (int): The number of highest peaks to return.\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "\n",
    "    Returns:\n",
    "        numpy array: An array of indices corresponding to the highest peaks in `ys`.\n",
    "\n",
    "    Bugs:\n",
    "        `num_of_peaks` cannot be greater than the number of detected peaks\n",
    "        `xs` or `ys` must be NumPy array\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    indxs, properties = find_peaks(ys)\n",
    "    return indxs[np.argsort(-ys[indxs])[:num_of_peaks]]\n",
    "\n",
    "def check_inputs(xs):\n",
    "    \"\"\"\n",
    "    \n",
    "    Checks whether the input array `xs` is sorted in ascending order.\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray or list): The input array to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: `True` if `xs` is sorted in ascending order, otherwise `False`.\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(len(xs)-1):\n",
    "        if xs[i] > xs[i+1]:\n",
    "            print(\"check_inputs(): input xs is badly ordered. Use reorder_inputs to reorder\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def reorder_inputs(xs,ys):\n",
    "    \"\"\"\n",
    "    \n",
    "    Reorders the input arrays `xs` and `ys` in ascending order of `xs`.\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "        \n",
    "    Returns:\n",
    "        tuple of numpy arrays (sorted xs, sorted ys)\n",
    "\n",
    "    Bugs:\n",
    "        `xs` or `ys` must be NumPy array\n",
    "        `xs` and `ys`must be same length\n",
    "        \n",
    "    \"\"\"\n",
    "    i = np.argsort(xs)\n",
    "    return xs[i], ys[i]\n",
    "\n",
    "#xlist is the teh index left to highest peak, highest peak, and the index right to teh highest peak\n",
    "def design_matrix(xlist): \n",
    "    \"\"\"\n",
    "    \n",
    "    Constructs a design matrix for quadratic curve fitting.\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "\n",
    "    Returns:\n",
    "        3 x 3 design matrix of numpy arrays\n",
    "\n",
    "    Bugs:\n",
    "        xlist must be an numpy array\n",
    "\n",
    "    Note:\n",
    "        Note the factor of 0.5 that Hogg likes and no one else\n",
    "        Also assumes xlist is ordered\n",
    "    \n",
    "    \"\"\"\n",
    "    return (np.vstack((xlist**0,xlist**1,0.5*xlist**2))).T\n",
    "\n",
    "def fit_parabola(xs, ys, index):\n",
    "    \"\"\"\n",
    "\n",
    "    Fits a quadratic function to three consecutive data points. Solves for coefficients (b,m,q) in the quadratic\n",
    "    f(x) = b + m*x + (1/2) * q * x^2\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "        index (int): The index of peak\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        tuple: (b, m, q)\n",
    "\n",
    "    Bugs: \n",
    "        index-1` or `index+2` can't be out of bounds\n",
    "        ``xs` or `ys` must be NumPy array\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    return np.linalg.solve(design_matrix(xs[index-1:index+2]), ys[index-1:index+2])\n",
    "\n",
    "def refine_peak(xs, ys, index):\n",
    "    \"\"\"\n",
    "\n",
    "    Refines the peak position using quadratic fit\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "        index (int): The index of peak\n",
    "    \n",
    "    Returns:\n",
    "        3-tuple: (x position of refined peak, y position of refined peak, and second derivative (q))\n",
    "\n",
    "    Bugs:\n",
    "        Must be synchronized with the design matrix\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    b,m,q = fit_parabola(xs, ys, index)\n",
    "    x_peak = -m / q\n",
    "    return x_peak, 0.5 * q * (x_peak) ** 2 + m * (x_peak) + b, q\n",
    "    \n",
    "def refine_peaks(xs, ys, indices):\n",
    "    \"\"\"\n",
    "\n",
    "    Refines the peak position for a set of indices using quadratic fit\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "        indices (numpy array): indices of the peaks (this should be the output of get_started()\n",
    "\n",
    "    Returns:\n",
    "        three  numpy arrays (array of refined x positions, array of refined y positions, and the second derivatives)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    foo = lambda i: refine_peak(xs,ys,i)\n",
    "    xs_refined, ys_refined, second_derivatives = zip(*list(map(foo,indices)))\n",
    "    return np.array(xs_refined), np.array(ys_refined), np.array(second_derivatives)\n",
    "\n",
    "\n",
    "def folding_freq(delta_f, fs, ps, sampling_time, makeplots=False):\n",
    "    \"\"\"\n",
    "    ##bugs:\n",
    "    - assumes fs are ordered\n",
    "    - global delta_f\n",
    "    \"\"\"\n",
    "    fc_guess = 1. / sampling_time\n",
    "    \n",
    "    IA = fs < 0.5 * fc_guess\n",
    "    fsA, psA = fs[IA], ps[IA]\n",
    "    fsA,psA  = fsA[2:-2],  psA[2:-2]\n",
    "    cs = CubicSpline(fs, ps, extrapolate=False)\n",
    "    \n",
    "    small, tiny = 20 * delta_f, 0.25 * delta_f\n",
    "    fc_candidates = np.arange(fc_guess - small, fc_guess + small, tiny)\n",
    "    foos_c = np.array([np.nansum(psA * cs(fc - fsA)) for fc in fc_candidates])\n",
    "    fc_index = get_started(1,fc_candidates, foos_c)\n",
    "    fc, _, _ = refine_peaks(fc_candidates, foos_c, fc_index)\n",
    "    fc = fc[0]\n",
    "    \n",
    "    if makeplots:\n",
    "        plt.plot(fc_candidates, foos_c)\n",
    "        plt.axvline(fc_guess)\n",
    "        plt.axvline(fc, color = 'red', alpha = 0.5)\n",
    "        plt.title(fc)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    return fc\n",
    "\n",
    "def find_min_and_refine(xs,ys):\n",
    "    indxs, properties = find_peaks(-ys)\n",
    "    min_index =  indxs[np.argsort(ys[indxs])[:1]]\n",
    "    refined_x, refined_y, second_derivative = refine_peaks(xs, ys, min_index)\n",
    "    return refined_x[0], refined_y[0]\n",
    "\n",
    "def get_filtered_peaks(num_of_peaks, xs, ys): \n",
    "    '''\n",
    "    ##bugs:\n",
    "    #- realizes on global variable f_avoid\n",
    "    '''\n",
    "    indxs, properties = find_peaks(ys)\n",
    "    indices = indxs[np.argsort(-ys[indxs])]\n",
    "\n",
    "    filtered = []\n",
    "    for index in indices:\n",
    "        if all(abs(xs[index] - xs[i]) >= (f_avoid) for i in filtered):\n",
    "            filtered.append(index)\n",
    "            if(len(filtered) >= num_of_peaks):\n",
    "                break\n",
    "    return np.array(filtered)\n",
    "\n",
    "def integral_design_matrix(ts, om, T):\n",
    "    \"\"\"\n",
    "    ##bugs:\n",
    "    - assumes all data points have the same exposure time, `T`\n",
    "    - not numerically stable when `om * T` is small\n",
    "    \"\"\"\n",
    "    return np.vstack([\n",
    "        np.ones_like(ts),\n",
    "        (+ np.sin(om * (ts + T/2)) - np.sin(om * (ts - T/2))) / (om * T),\n",
    "        (- np.cos(om * (ts + T/2)) + np.cos(om * (ts - T/2))) / (om * T)\n",
    "    ]).T\n",
    "\n",
    "def weighted_least_squares(A, b, weights):\n",
    "    ATA = A.T @ (A * weights[:, np.newaxis])\n",
    "    ATb = A.T @ (b * weights)\n",
    "    return A @ np.linalg.solve(ATA, ATb)\n",
    "\n",
    "def weighted_least_squares_new(A, b, weights):\n",
    "    ATA = A.T @ (A * weights[:, np.newaxis])\n",
    "    ATb = A.T @ (b * weights)\n",
    "    trace = np.trace(ATA)\n",
    "    det = np.linalg.det(ATA)\n",
    "    return np.linalg.solve(ATA, ATb), ATA\n",
    "\n",
    "def integral_chi_squared(om, ts, ys, ws, T):\n",
    "    A = integral_design_matrix(ts, om, T)\n",
    "    return np.sum(ws * (ys - weighted_least_squares(A, ys, ws))**2)\n",
    "\n",
    "def region_and_freq(indices, folding_freq, f_min, unrefined_freq, unrefined_power):\n",
    "    \n",
    "    regions, best_freqs, best_chi2s = [], [], []\n",
    "\n",
    "    for i in range(len(indices)):\n",
    "        fas, __, __ = refine_peaks(unrefined_freq, unrefined_power, indices)\n",
    "        A, B, C = fas, folding_freq-fas, folding_freq+fas\n",
    "        \n",
    "        fine_freqsA = np.arange(A[i] - 5 * f_min, A[i] + 5 * f_min, 0.2 * f_min)  \n",
    "        chi2_fineA = np.array([integral_chi_squared(2. * np.pi * f, t_fit, flux_fit, weight_fit, lc_exptime) for f in fine_freqsA])\n",
    "        best_freqA, best_chi2A = find_min_and_refine(fine_freqsA,chi2_fineA)\n",
    "    \n",
    "        fine_freqsB = np.arange(B[i]- 5 * f_min, B[i] + 5 * f_min, 0.2 * f_min)  \n",
    "        chi2_fineB = np.array([integral_chi_squared(2. * np.pi * f, t_fit, flux_fit, weight_fit, lc_exptime) for f in fine_freqsB])\n",
    "        best_freqB, best_chi2B = find_min_and_refine(fine_freqsB,chi2_fineB)\n",
    "    \n",
    "        fine_freqsC = np.arange(C[i] - 5 * f_min, C[i] + 5 * f_min, 0.2 * f_min)  \n",
    "        chi2_fineC = np.array([integral_chi_squared(2. * np.pi * f, t_fit, flux_fit, weight_fit, lc_exptime) for f in fine_freqsC])\n",
    "        best_freqC, best_chi2C = find_min_and_refine(fine_freqsC,chi2_fineC)\n",
    "        \n",
    "        #print(best_chi2A, best_chi2B, best_chi2C)\n",
    "\n",
    "        if (best_chi2A <= best_chi2B and best_chi2A <= best_chi2C):\n",
    "            regions.append(\"A\")\n",
    "            best_freqs.append(best_freqA)\n",
    "            best_chi2s.append(best_chi2A)\n",
    "            \n",
    "        elif (best_chi2B < best_chi2A and best_chi2B < best_chi2C):\n",
    "            #print(\"here\")\n",
    "            regions.append(\"B\")\n",
    "            best_freqs.append(best_freqB)\n",
    "            best_chi2s.append(best_chi2B)\n",
    "            \n",
    "        elif (best_chi2C < best_chi2A and best_chi2C < best_chi2B):\n",
    "            #print(\"herec\")\n",
    "            regions.append(\"C\")\n",
    "            best_freqs.append(best_freqC)\n",
    "            best_chi2s.append(best_chi2C)\n",
    "\n",
    "\n",
    "    return(regions, best_freqs, best_chi2s)\n",
    "\n",
    "\n",
    "def check_coherence(ts, ys, weights, final_freqs):\n",
    "    '''assumes a lot of thing about the data\n",
    "    '''\n",
    "  \n",
    "    oms = np.array([(f * 2 * np.pi) for f in final_freqs])\n",
    "\n",
    "    a_early, a_late, b_early, b_late, invvars = [], [], [], [], []\n",
    "    \n",
    "    ts_median = np.median(ts)\n",
    "    \n",
    "    cases = [(ts < ts_median, \"early\"),\n",
    "             (ts > ts_median, \"late\")]\n",
    "    \n",
    "    for om in oms:\n",
    "        \n",
    "        for I, name in cases:\n",
    "            A = integral_design_matrix(ts[I], om, lc_exptime)\n",
    "            pars, ___ = weighted_least_squares_new(A, ys[I], weights[I])\n",
    "            a,b = pars[1], pars[2]\n",
    "            \n",
    "            if name == \"early\":\n",
    "                a_early.append(pars[1])\n",
    "                b_early.append(pars[2])\n",
    "            elif name == \"late\":\n",
    "                a_late.append(pars[1])\n",
    "                b_late.append(pars[2])\n",
    "\n",
    "    return a_early, a_late, b_early, b_late\n",
    "            \n",
    "def change_in_phase_and_amp(a_early, a_late, b_early, b_late, ts):\n",
    "\n",
    "    rates_of_phases = []\n",
    "    rates_of_amps = []\n",
    "    ts_median = np.median(ts)\n",
    "    delta_t = np.median(ts[ts>ts_median]) - np.median(ts[ts < ts_median])\n",
    "\n",
    "    \n",
    "\n",
    "    for a_earl_grey, a_latte, b_earl_grey, b_latte in zip(a_early, a_late, b_early, b_late):\n",
    "    \n",
    "\n",
    "        delta_r = [a_latte - a_earl_grey, b_latte - b_earl_grey]\n",
    "        vector_r = [0.5 * (a_latte + a_earl_grey), 0.5 * (b_latte + b_earl_grey)]\n",
    "\n",
    "        cross_z = delta_r[0] * vector_r[1] - delta_r[1] * vector_r[0]\n",
    "        phase = (1 / delta_t) * (cross_z / np.dot(vector_r, vector_r))\n",
    "        rates_of_phases.append(phase)\n",
    "        \n",
    "        amplitude = (1/(delta_t)) * (np.dot(delta_r, vector_r) / np.dot(vector_r, vector_r))\n",
    "        rates_of_amps.append(amplitude)\n",
    "\n",
    "    return (rates_of_phases, rates_of_amps)\n",
    "\n",
    "def null_chi_squared(ts, ys, weights):\n",
    "\n",
    "    a0 = np.sum(weights * ys) / np.sum(weights)\n",
    "    null_chisq = np.sum(weights * (ys - a0) ** 2)\n",
    "    return null_chisq\n",
    "\n",
    "def sharpness(second_derivatives, y_news):\n",
    "    sharps = []\n",
    "    for second_derivative, y_new in zip(second_derivatives, y_news):\n",
    "        sharpness = (-second_derivative/y_new)**(1/2)\n",
    "        sharps.append(sharpness)\n",
    "    return sharps\n",
    "\n",
    "def star(kic_id):\n",
    "    search_result = lk.search_lightcurve(kic_id, mission='Kepler')\n",
    "    lc_collection = search_result.download_all()\n",
    "    lc = lc_collection.stitch()\n",
    "    delta_f = (1/(lc.time[-1] - lc.time[0]).value)\n",
    "    sampling_time= np.median(np.diff(lc.time.value))\n",
    "\n",
    "    return (lc, delta_f, sampling_time)\n",
    "\n",
    "def mask_vals(lc):\n",
    "\n",
    "    t_clean = np.ma.filled(lc.time.value, np.nan)\n",
    "    flux_clean = np.ma.filled(lc.flux.value, np.nan)\n",
    "    sigma_clean = np.ma.filled(lc.flux_err.value, np.nan)\n",
    "\n",
    "    mask = np.isfinite(t_clean) & np.isfinite(flux_clean) & np.isfinite(sigma_clean)\n",
    "\n",
    "    t_fit = t_clean[mask]\n",
    "    flux_fit = flux_clean[mask]\n",
    "    sigma_fit = sigma_clean[mask]\n",
    "    weight_fit = 1 / sigma_fit**2\n",
    "\n",
    "    return(t_fit, flux_fit,weight_fit)\n",
    "\n",
    "def pg_full(f_min, f_max, lc):\n",
    "\n",
    "    frequency_grid_full = np.arange(f_min, f_max, f_min)/(u.day)\n",
    "\n",
    "    pg_full = lc.to_periodogram(\n",
    "        method='lombscargle',\n",
    "        normalization='psd',\n",
    "    frequency=frequency_grid_full\n",
    "    )\n",
    "\n",
    "    power_full = pg_full.power.value\n",
    "    freq_full = pg_full.frequency.to(1/u.day).value\n",
    "\n",
    "    return(freq_full, power_full)\n",
    "\n",
    "def pg_mini(f_min, f_max, lc):\n",
    "\n",
    "    frequency_grid_mini = np.arange(f_min, f_max / 3, f_min) / (u.day)\n",
    "\n",
    "    pg_mini = lc.to_periodogram(\n",
    "        method='lombscargle',\n",
    "        normalization='psd',\n",
    "        frequency=frequency_grid_mini\n",
    "    )\n",
    "\n",
    "    power_mini = pg_mini.power.value\n",
    "    freq_mini = pg_mini.frequency.to(1/u.day).value\n",
    "\n",
    "    return(freq_mini, power_mini)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72b1d66-69cc-4f6c-ad2e-8a7c62bc7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc, delta_f, sampling_time = nana.star('KIC 5202905')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd953fb4-9622-466b-a74e-8286978f969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_max = (3 / (2*sampling_time))\n",
    "f_min = delta_f/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe36779-a54b-407a-8055-48ca65ad32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_fit, flux_fit, weight_fit = nana.mask_vals(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cb17ef8-a7c3-49b9-97a3-f2bb5710e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_full, power_full = nana.pg_full(f_min, f_max, lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9765ba8e-729d-4526-aace-054eec29de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_mini, power_mini = nana.pg_mini(f_min, f_max, lc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ed4249-706a-4afc-bef1-92ed69014948",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = nana.get_filtered_peaks(12, freq_mini, power_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aaa5c3d-558e-4d40-8d51-e5ebf51808ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "___, refined_power, second_derivatives = nana.refine_peaks(freq_mini, power_mini, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d8f6d94-2359-4b6d-a806-92e1e470c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nana.folding_freq(delta_f, freq_full, power_full, sampling_time, False)\n",
    "#fc = folding_freq(delta_f, freq_full, power_full, sampling_time, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53486fe5-feb5-4f1d-a3ce-b7dd0da59888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regions, final_freqs, chi2s = nana.region_and_freq(indices, fc, f_min, freq_mini, power_mini)\n",
    "regions, final_freqs, chi2s = nana.region_and_freq(indices, fc, f_min, freq_mini, power_mini, t_fit, flux_fit, weight_fit)\n",
    "#add, ts, flux, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b961d7f-a695-4740-822c-f8a281a5747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_early, a_late, b_early, b_late = nana.check_coherence(t_fit, flux_fit, weight_fit, final_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3669db-8053-4e68-804d-f38017f6223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_of_phase, rate_of_amp = nana.change_in_phase_and_amp(a_early, a_late, b_early, b_late, t_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "433fe4d8-ab95-4f5d-ab6d-7762e79d9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_chi2s = nana.null_chi_squared(t_fit, flux_fit, weight_fit) - chi2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e173bd7-a637-4258-9259-eb4658e84bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpnesses = nana.sharpness(second_derivatives, refined_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086996c2-3ded-402f-acf1-fa8f859f6820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
