{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80df3876-0a5f-48a8-9652-cf5b1e6fad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import scipy.signal\n",
    "from astropy import units as u\n",
    "from scipy.interpolate import CubicSpline\n",
    "from datetime import datetime\n",
    "import os\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "from lightkurve import LightCurve\n",
    "from lightkurve import LightkurveError\n",
    "import time\n",
    "\n",
    "f_avoid = 3.5 / 372.5\n",
    "lc_exptime = (29.4) / (60 * 24) #days, see Kepler Data Processing Handbook, Section 3.1\n",
    "sc_exptime = (58.8) / (60 * 60 * 24) #days, see Kepler Data Processing Handbook, Section 3.1\n",
    "\n",
    "def star(kic_id, exptime='long'):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `kic_id`: Kepler ID (str)\n",
    "    `exptime`: desired exposure time string (default `'long'`), e.g., `'long'` or `'short'`\n",
    "\n",
    "    ## Outputs:\n",
    "    Returns a 4-tuple:\n",
    "    - `lc`: stitched Lightkurve LightCurve object (or None if failed)\n",
    "    - `delta_f`: frequency resolution, 1 / total observation time\n",
    "    - `sampling_time`: median time between observations (in days)\n",
    "    - `exptime`:  exposure time in days (from global `lc_exptime` or `sc_exptime`)\n",
    "\n",
    "    ## Bugs:\n",
    "    - Depends on external globals: `lc_exptime`, `sc_exptime` \n",
    "    - Fails silently when no data found (returns `None` tuple but doesn't raise)\n",
    "    - Rejects light curves where any `dt < 0.9 * median(dt)` â€” may be too strict\n",
    "    - No handling of NaNs, gaps, or outliers in flux or time\n",
    "    - Assumes time sampling regularity based on hardcoded magic thresholds\n",
    "    \"\"\"\n",
    "     \n",
    "    search_result = lk.search_lightcurve(kic_id, mission = 'Kepler', exptime=exptime)\n",
    "    \n",
    "\n",
    "    if len(search_result) < 1:\n",
    "        print(f\"nana.star(): no results for {kic_id} at this cadence\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    try:\n",
    "        lc_collection = search_result.download_all()\n",
    "    \n",
    "    except LightkurveError as e:\n",
    "        print(f\"LightkurveError for {kic_id}: {e}\")\n",
    "\n",
    "        try:\n",
    "            path = str(e).split(\"\\n\")[1].strip()  # extract path from error message\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "                print(f\"Deleted corrupt file: {path}\")\n",
    "                # Retry download once\n",
    "                lc_collection = search_result.download_all()\n",
    "                lc = lc_collection.stitch()\n",
    "            else:\n",
    "                print(f\"Path not found: {path}\")\n",
    "                return None, None, None, None\n",
    "        except Exception as delete_error:\n",
    "            print(f\"Retry failed for {kic_id}: {delete_error}\")\n",
    "            return None, None, None, None\n",
    "    \n",
    "    lc = lc_collection.stitch()\n",
    "    time, flux = reorder_inputs(lc.time.value, lc.flux.value)\n",
    "\n",
    "    if not np.all(np.diff(time) > 0):\n",
    "        print(\"nana.star(): times not in order\")\n",
    "        #raise ValueError(\"Times are not in order\")\n",
    "    delta_f = (1/(time[-1] - time[0]))\n",
    "    sampling_time= np.median(np.diff(time))\n",
    "    \n",
    "\n",
    "\n",
    "    if not np.all(np.diff(time) > 0.90 * sampling_time): #magic\n",
    "        print(\"nana.star(): some time intervals out of spec\")\n",
    "        print(\"nana.star(): median dt = \", sampling_time)\n",
    "        #raise ValueError(\"some time intervals out of spec\")\n",
    "    \n",
    "    exptime = None\n",
    "    if sampling_time > 0.9 * lc_exptime: \n",
    "        exptime = lc_exptime\n",
    "    if sampling_time < 1.1 * sc_exptime:\n",
    "        exptime = sc_exptime\n",
    "    if exptime is None:\n",
    "        print(\"nana.star(): no consistent exptime\")\n",
    "        #raise ValueError(\"no consistent exptime\")\n",
    "\n",
    "    return lc, delta_f, sampling_time, exptime\n",
    "\n",
    "def check_inputs(xs):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: list or numpy array of values (typically time values)\n",
    "\n",
    "    ## Outputs:\n",
    "    `bool`: `True` if the array is sorted in ascending order, `False` otherwise\n",
    "\n",
    "    ## Bugs:\n",
    "    - Prints an error message but doesn't raise an exception when input is unsorted\n",
    "    \"\"\"\n",
    "    for i in range(len(xs) - 1):\n",
    "        if xs[i] > xs[i + 1]:\n",
    "            print(\"check_inputs(): input xs is badly ordered. Use reorder_inputs to reorder\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def reorder_inputs(xs, ys):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: numpy array of x-axis values  \n",
    "    `ys`: numpy array of y-axis values \n",
    "\n",
    "    ## Outputs:\n",
    "    A tuple `(xs_sorted, ys_sorted)` where:\n",
    "    - `xs_sorted`: `xs` sorted in ascending order\n",
    "    - `ys_sorted`: corresponding `ys` values reordered to match `xs_sorted`\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `xs` and `ys` are NumPy arrays\n",
    "    - No error handling for NaNs or non-numeric values\n",
    "    - Raises a ValueError if `xs` and `ys` have different lengths\n",
    "    \"\"\"\n",
    "    if len(xs) != len(ys):\n",
    "        raise ValueError(\"reorder_inputs(): `xs` and `ys` must be the same length\")\n",
    "    i = np.argsort(xs)\n",
    "    return xs[i], ys[i]\n",
    "\n",
    "\n",
    "def design_matrix(xlist):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xlist`: numpy array of length 3\n",
    "\n",
    "    ## Outputs:\n",
    "    A 3x3 design matrix:\n",
    "    - Column 1: constant term (1s)\n",
    "    - Column 2: linear term (`xlist`)\n",
    "    - Column 3: quadratic term with 0.5 factor (`0.5 * xlist**2`)\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `xlist` is a NumPy array (will raise if not)\n",
    "    - Assumes `xlist` has length 3 \n",
    "    - Assumes `xlist` is ordered\n",
    "\n",
    "    ## Notes:\n",
    "    - Includes a 0.5 factor that Hogg likes in the quadratic term \n",
    "    - Raises a `TypeError` if input is not a NumPy array\n",
    "    \"\"\"\n",
    "    return (np.vstack((xlist**0, xlist**1, 0.5 * xlist**2))).T\n",
    "\n",
    "def fit_parabola(xs, ys, index):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: numpy array of x values  \n",
    "    `ys`: numpy array of y values (same length as `xs`)  \n",
    "    `index`: integer index of the central point to fit around\n",
    "\n",
    "    ## Outputs:\n",
    "    Tuple `(b, m, q)` representing coefficients of the quadratic:  \n",
    "\n",
    "    ## Bugs:\n",
    "    - `xs` and `ys` must be numpy arrays\n",
    "    - Index must not be 0 or `len(xs) - 1`; otherwise slice will be out of bounds\n",
    "    - Assumes `xs` is ordered\n",
    "    \"\"\"\n",
    "\n",
    "    if index < 1 or index > len(xs) - 2:\n",
    "        raise IndexError(\"fit_parabola(): index must be between 1 and len(xs) - 2\")\n",
    "    \n",
    "    return np.linalg.solve(design_matrix(xs[index-1:index+2]), ys[index-1:index+2])\n",
    "\n",
    "def refine_peak(xs, ys, index):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: numpy array of x values (frequencies)  \n",
    "    `ys`: numpy array of y values (power)  \n",
    "    `index`: integer index of peak to refine\n",
    "\n",
    "    ## Outputs:\n",
    "    3-tuple `(x_peak, y_peak, q)` where:\n",
    "    - `x_peak`: refined x-position of the peak \n",
    "    - `y_peak`: refined y-position\n",
    "    - `q`: second derivative\n",
    "\n",
    "    ## Bugs:\n",
    "    - Must be synchronized with the design matrix (uses same quadratic form)\n",
    "    \"\"\"\n",
    "    b, m, q = fit_parabola(xs, ys, index)\n",
    "    x_peak = -m / q\n",
    "    y_peak = 0.5 * q * x_peak**2 + m * x_peak + b\n",
    "    return x_peak, y_peak, q\n",
    "\n",
    "def refine_peaks(xs, ys, indices):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: numpy array of x values  \n",
    "    `ys`: numpy array of y values (same length as `xs`)  \n",
    "    `indices`: numpy array of peak indices\n",
    "\n",
    "    ## Outputs:\n",
    "    Three NumPy arrays:\n",
    "    - `xs_refined`: refined x positions of peaks\n",
    "    - `ys_refined`: refined y positions of peaks\n",
    "    - `second_derivatives`: curvature values (second derivative q for each peak)\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all `indices` are valid (i.e., between 1 and len(xs) - 2)\n",
    "    - Assumes `xs` and `ys` are numpy arrays and ordered\n",
    "    \"\"\"\n",
    "    #results = list(map(check_refine, indices))\n",
    "    # xs_refined, ys_refined, second_derivatives = zip(\n",
    "    #     *[(r if r is not None else (None, None, None)) for r in results]\n",
    "    # )\n",
    "\n",
    "    #foo = lambda i: refine_peak(xs, ys, i)\n",
    "    #xs_refined, ys_refined, second_derivatives = zip(*map(foo, indices))\n",
    "\n",
    "    n = len(indices)\n",
    "    xs_refined = np.full(n, None)\n",
    "    ys_refined = np.full(n, None)\n",
    "    second_derivatives = np.full(n, None)\n",
    "\n",
    "    for j, i in enumerate(indices):\n",
    "        result = check_refine(xs, ys, i)\n",
    "        if result is not None:\n",
    "            x_r, y_r, q_r = result\n",
    "            xs_refined[j] = x_r\n",
    "            ys_refined[j] = y_r\n",
    "            second_derivatives[j] = q_r\n",
    "\n",
    "    return np.array(xs_refined), np.array(ys_refined), np.array(second_derivatives)\n",
    "\n",
    "def check_refine(xs, ys, i):\n",
    "        if i is None:\n",
    "            return None\n",
    "        try:\n",
    "            return refine_peak(xs, ys, i)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "\n",
    "def folding_freq(delta_f, fs, ps, sampling_time, makeplots=False):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `delta_f`: frequency resolution\n",
    "    `fs`: numpy array of frequency values (assumed ordered)  \n",
    "    `ps`: numpy array of power values corresponding to `fs`  \n",
    "    `sampling_time`: sampling interval in days  \n",
    "    `makeplots`: bool, whether to plot\n",
    "\n",
    "    ## Outputs:\n",
    "    `fc`: refined estimate of the folding frequency\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `fs` is strictly ordered (required for spline and peak detection)\n",
    "    - No check for NaNs in `fs` or `ps`\n",
    "    - Removes first and last two points (`fsA = fsA[2:-2]`), assumes enough data\n",
    "    - No check for empty result from `get_filtered_peaks`\n",
    "    - Assumes `refine_peaks` will succeed and return at least one result\n",
    "    - Assumes `CubicSpline(fs, ps)` works without NaNs or duplicate x-values\n",
    "    \"\"\"\n",
    "    fc_guess = 1. / sampling_time\n",
    "    IA = fs < 0.5 * fc_guess\n",
    "    fsA, psA = fs[IA], ps[IA]\n",
    "    fsA, psA = fsA[2:-2], psA[2:-2]\n",
    "\n",
    "    cs = CubicSpline(fs, ps, extrapolate=False)\n",
    "\n",
    "    small, tiny = 20 * delta_f, 0.25 * delta_f\n",
    "    fc_candidates = np.arange(fc_guess - small, fc_guess + small, tiny)\n",
    "    foos_c = np.array([np.nansum(psA * cs(fc - fsA)) for fc in fc_candidates])\n",
    "\n",
    "    fc_index = get_filtered_peaks(1, fc_candidates, foos_c)\n",
    "    fc, _, _ = refine_peaks(fc_candidates, foos_c, fc_index)\n",
    "    fc = fc[0]\n",
    "\n",
    "    if makeplots:\n",
    "        plt.plot(fc_candidates, foos_c)\n",
    "        plt.axvline(fc_guess)\n",
    "        plt.axvline(fc, color='red', alpha=0.5)\n",
    "        plt.title(f\"Refined folding frequency: {fc:0.5f}\")\n",
    "        plt.show()\n",
    "\n",
    "    return fc\n",
    "\n",
    "def find_min_and_refine(xs, ys):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: numpy array of x values  \n",
    "    `ys`: numpy array of y values \n",
    "\n",
    "    ## Outputs:\n",
    "    Tuple `(refined_x, refined_y)` where:\n",
    "    - `refined_x`: x-position of the refined minimum\n",
    "    - `refined_y`: y-value at the refined minimum\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `xs` and `ys` are NumPy arrays of equal length\n",
    "    - Assumes `xs` is ordered\n",
    "    - Raises `ValueError` if no local minima are found\n",
    "    - Raises `IndexError` if minimum is at the edge (index 0 or len-1)\n",
    "    \"\"\"\n",
    "    indxs, _ = find_peaks(-ys)\n",
    "\n",
    "    if len(indxs) == 0:\n",
    "        return None, None\n",
    "        #raise ValueError(\"find_min_and_refine(): no local minima found\")\n",
    "    \n",
    "    min_index = indxs[np.argsort(ys[indxs])[:1]]\n",
    "    if min_index < 1 or min_index > len(xs) - 2:\n",
    "        raise IndexError(\"find_min_and_refine(): minimum too close to edge to refine\")\n",
    "    \n",
    "    refined_x, refined_y, _ = refine_peaks(xs, ys, min_index)\n",
    "    return refined_x[0], refined_y[0]\n",
    "\n",
    "def get_filtered_peaks(num_of_peaks, xs, ys):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `num_of_peaks`: number of peaks to return  \n",
    "    `xs`: numpy array of x values (frequencies)  \n",
    "    `ys`: numpy array of y values (power spectrum)\n",
    "\n",
    "    ## Outputs:\n",
    "    NumPy array of peak indices (length â‰¤ `num_of_peaks`), filtered to avoid clustering\n",
    "\n",
    "    ## Bugs:\n",
    "    - Depends on global variable `f_avoid`, which must be defined externally\n",
    "    - Assumes `xs` is ordered and evenly spaced\n",
    "    - No NaN handling in `ys`\n",
    "    \"\"\"\n",
    "    indxs, _ = find_peaks(ys)\n",
    "    if len(indxs) == 0:\n",
    "        raise ValueError(\"get_filtered_peaks(): no peaks found in `ys`\")\n",
    "    \n",
    "    indices = indxs[np.argsort(-ys[indxs])]\n",
    "\n",
    "    if (len(indices) < num_of_peaks):\n",
    "        print(f\"get_filtered_peaks(): fewer than {num_of_peaks} peaks found, will return None for missing peaks\")\n",
    "\n",
    "    filtered = []\n",
    "    for index in indices:\n",
    "        if all(abs(xs[index] - xs[i]) >= f_avoid for i in filtered):\n",
    "            filtered.append(index)\n",
    "            if len(filtered) >= num_of_peaks:\n",
    "                break\n",
    "\n",
    "    while len(filtered) < num_of_peaks:\n",
    "        filtered.append(None)\n",
    "    return np.array(filtered)\n",
    "\n",
    "\n",
    "def inject_one_mode(ts, ys, T, in_pars):\n",
    "    #yin is the new fluxfit\n",
    "    fin, ain, bin = in_pars\n",
    "    inject_vec = np.array([0.0, ain, bin])   \n",
    "\n",
    "    xin = integral_design_matrix(ts, 2 * np.pi * fin, T)\n",
    "    yin = ys + xin @ inject_vec  \n",
    "    \n",
    "    return yin \n",
    "\n",
    "\n",
    "def integral_design_matrix(ts, om, T):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `ts`: list of N times (days)\n",
    "    `om`: angular frequency (inverse days)\n",
    "    `T`: exposure time (days)\n",
    "\n",
    "    ## Outputs:\n",
    "    `X`: Nx3 design matrix\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all data points have the same exposure time `T`\n",
    "    - Not numerically stable when `om * T` is small\n",
    "    \"\"\"\n",
    "    return np.vstack([\n",
    "        np.ones_like(ts),\n",
    "        (np.sin(om * (ts + T / 2)) - np.sin(om * (ts - T / 2))) / (om * T),\n",
    "        (-np.cos(om * (ts + T / 2)) + np.cos(om * (ts - T / 2))) / (om * T)\n",
    "    ]).T\n",
    "\n",
    "def weighted_least_squares(A, b, weights):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `A`: NxM design matrix (NumPy array)  \n",
    "    `b`: N-length observation vector (NumPy array)  \n",
    "    `weights`: N-length vector of weights (NumPy array), applied per row\n",
    "\n",
    "    ## Outputs:\n",
    "    N-length fitted model values `A @ x`, where `x` solves the weighted least squares problem\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all inputs are NumPy arrays of compatible shape\n",
    "    \"\"\"\n",
    "\n",
    "    ATA = A.T @ (A * weights[:, np.newaxis])\n",
    "    ATb = A.T @ (b * weights)\n",
    "    return A @ np.linalg.solve(ATA, ATb)\n",
    "\n",
    "def weighted_least_squares_new(A, b, weights):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `A`: NxM design matrix (NumPy array)  \n",
    "    `b`: N-length observation vector (NumPy array)  \n",
    "    `weights`: N-length vector of weights (NumPy array), applied per row\n",
    "\n",
    "    ## Outputs:\n",
    "    Tuple `(x, ATA)` where:\n",
    "    - `x`: solution to the weighted least squares problem (Mx1 coefficient vector)\n",
    "    - `ATA`: weighted normal matrix `Aáµ€ W A`, useful for diagnostics\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all inputs are NumPy arrays with compatible dimensions\n",
    "    \"\"\"\n",
    "    ATA = A.T @ (A * weights[:, np.newaxis])\n",
    "    ATb = A.T @ (b * weights)\n",
    "    return np.linalg.solve(ATA, ATb), ATA\n",
    "\n",
    "def integral_chi_squared(om, ts, ys, ws, T):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `om`: angular frequency (in inverse days)  \n",
    "    `ts`: numpy array of observation times (in days)  \n",
    "    `ys`: numpy array of observed flux values  \n",
    "    `ws`: numpy array of weights (same length as `ts` and `ys`)  \n",
    "    `T`: exposure time (in days)\n",
    "\n",
    "    ## Outputs:\n",
    "    Weighted chi-squared value computed using the integral design matrix model\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all inputs are NumPy arrays of compatible shapes\n",
    "    - Assumes uniform exposure time `T` for all observations\n",
    "    - Numerically unstable when `om * T` is small (from `integral_design_matrix`)\n",
    "    \"\"\"\n",
    "    A = integral_design_matrix(ts, om, T)\n",
    "    return np.sum(ws * (ys - weighted_least_squares(A, ys, ws))**2)\n",
    "\n",
    "def region_and_freq(indices, folding_freq, f_min, unrefined_freq, unrefined_power, t_fit, flux_fit, weight_fit, T):\n",
    "\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `indices`: array of peak indices\n",
    "    `folding_freq`: folding frequency   \n",
    "    `df`: frequency resolution\n",
    "    `unrefined_freq`: array of frequency values  \n",
    "    `unrefined_power`: power spectrum values corresponding to `unrefined_freq`  \n",
    "    `t_fit`: time values used for model fitting  \n",
    "    `flux_fit`: observed signal (e.g., flux)  \n",
    "    `weight_fit`: weights for fitting  \n",
    "    `T`: exposure time in days\n",
    "\n",
    "    ## Outputs:\n",
    "    Three NumPy arrays:\n",
    "    - `regions`: array of region labels (`\"A\"`, `\"B\"`, `\"C\"`)\n",
    "    - `best_freqs`: refined frequency values for each peak\n",
    "    - `best_chi2s`: corresponding chi-squared values\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `refine_peaks` succeeds for all given indices\n",
    "    - No handling if `fine_freqsX` are empty or out of bounds\n",
    "    \"\"\"\n",
    "    valid_locs = [j for j, val in enumerate(indices) if val is not None]\n",
    "    valid_indices = [indices[j] for j in valid_locs]\n",
    "    \n",
    "    N = len(indices)\n",
    "    regions = np.full(N, None)\n",
    "    best_freqs = np.full(N, None)\n",
    "    best_chi2s = np.full(N, None)\n",
    "\n",
    "    fas, _, _ = refine_peaks(unrefined_freq, unrefined_power, valid_indices)\n",
    "    \n",
    "    A, B, C = fas, folding_freq - fas, folding_freq + fas\n",
    "\n",
    "\n",
    "    for i, loc in enumerate(valid_locs):\n",
    "        fine_freqsA = np.arange(A[i] - 5 * f_min, A[i] + 5 * f_min, 0.2 * f_min)\n",
    "        chi2_fineA = np.array([integral_chi_squared(2 * np.pi * f, t_fit, flux_fit, weight_fit, T) for f in fine_freqsA])\n",
    "        best_freqA, best_chi2A = find_min_and_refine(fine_freqsA, chi2_fineA)\n",
    "        \n",
    "\n",
    "        fine_freqsB = np.arange(B[i] - 5 * f_min, B[i] + 5 * f_min, 0.2 * f_min)\n",
    "        chi2_fineB = np.array([integral_chi_squared(2 * np.pi * f, t_fit, flux_fit, weight_fit, T) for f in fine_freqsB])\n",
    "        best_freqB, best_chi2B = find_min_and_refine(fine_freqsB, chi2_fineB)\n",
    "\n",
    "        fine_freqsC = np.arange(C[i] - 5 * f_min, C[i] + 5 * f_min, 0.2 * f_min)\n",
    "        chi2_fineC = np.array([integral_chi_squared(2 * np.pi * f, t_fit, flux_fit, weight_fit, T) for f in fine_freqsC])\n",
    "        best_freqC, best_chi2C = find_min_and_refine(fine_freqsC, chi2_fineC)\n",
    "\n",
    "        freqs = np.array([best_freqA, best_freqB, best_freqC])\n",
    "        chi2s = np.array([best_chi2A, best_chi2B, best_chi2C])\n",
    "        regs = np.array(['A', 'B', 'C'])\n",
    "\n",
    "        no_nones = np.array([c is not None for c in chi2s])\n",
    "\n",
    "        if np.any(no_nones):\n",
    "            freqs = freqs[no_nones]\n",
    "            chi2s = chi2s[no_nones]\n",
    "            regs = regs[no_nones]\n",
    "\n",
    "            low_chi_ind = np.argmin(chi2s)\n",
    "            regions[loc] = regs[low_chi_ind]\n",
    "            best_freqs[loc] = freqs[low_chi_ind]\n",
    "            best_chi2s[loc] = chi2s[low_chi_ind]\n",
    "        else:\n",
    "            regions[loc] = None\n",
    "            best_freqs[loc] = None\n",
    "            best_chi2s[loc] = None\n",
    "\n",
    "    return regions, best_freqs, best_chi2s\n",
    "\n",
    "def check_coherence(ts, ys, weights, final_freq, T):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `ts`: numpy array of time values  \n",
    "    `ys`: numpy array of signal values (flux)  \n",
    "    `weights`: numpy array of weights  \n",
    "    `final_freq`: numpy array of refined frequencies \n",
    "    `T`: exposure time \n",
    "\n",
    "    ## Outputs:\n",
    "    Four NumPy arrays:\n",
    "    - `a_early`: sine amplitudes before the median time  \n",
    "    - `a_late`: sine amplitudes after the median time  \n",
    "    - `b_early`: cosine amplitudes before the median time  \n",
    "    - `b_late`: cosine amplitudes after the median time\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `ts`, `ys`, and `weights` are NumPy arrays of the same length\n",
    "    - Assumes design matrix and fit always succeed on each slice\n",
    "    - Assumes data can be cleanly split at the median time\n",
    "    \"\"\"\n",
    "    N = len(final_freq)\n",
    "    a_early, a_late, b_early, b_late = (np.full(N, None) for _ in range(4))\n",
    "\n",
    "    ts_median = np.median(ts)\n",
    "    I_early = ts < ts_median\n",
    "    I_late  = ts > ts_median\n",
    "\n",
    "    for inx, f in enumerate(final_freq):\n",
    "\n",
    "        if f is None:\n",
    "            continue\n",
    "        \n",
    "        om = 2 * np.pi * f\n",
    "\n",
    "        A_early = integral_design_matrix(ts[I_early], om, T)\n",
    "        pars_early, _ = weighted_least_squares_new(A_early, ys[I_early], weights[I_early])\n",
    "        a_early[inx] = pars_early[1]\n",
    "        b_early[inx] = pars_early[2]\n",
    "\n",
    "        A_late = integral_design_matrix(ts[I_late], om, T)\n",
    "        pars_late, _ = weighted_least_squares_new(A_late, ys[I_late], weights[I_late])\n",
    "        a_late[inx] = pars_late[1]\n",
    "        b_late[inx] = pars_late[2]\n",
    "\n",
    "    return a_early, a_late, b_early, b_late\n",
    "\n",
    "def safe_arr(arr):\n",
    "    return [np.nan if v is None else v for v in arr]\n",
    "\n",
    "def change_in_phase_and_amp(a_early, a_late, b_early, b_late, ts):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `a_early`, `a_late`, `b_early`, `b_late`: NumPy arrays of sine and cosine amplitudes  \n",
    "    `ts`: NumPy array of time values\n",
    "\n",
    "    ## Outputs:\n",
    "    Two NumPy arrays:\n",
    "    - `rates_of_phases`: estimated rate of phase change  \n",
    "    - `rates_of_amps`: estimated rate of amplitude change\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all input arrays are the same length\n",
    "    - Assumes clean median split in time\n",
    "    \"\"\"\n",
    "    N = len(a_early)\n",
    "    rates_of_phases = np.full(N, None)\n",
    "    rates_of_amps = np.full(N, None)\n",
    "\n",
    "    ts_median = np.median(ts)\n",
    "    delta_t = np.median(ts[ts > ts_median]) - np.median(ts[ts < ts_median])\n",
    "\n",
    "    for i in range(N):\n",
    "        if a_early[i] is None or a_late[i] is None or b_early[i] is None or b_late[i] is None:\n",
    "            continue\n",
    "        a_earl_grey = a_early[i]\n",
    "        a_latte     = a_late[i]\n",
    "        b_earl_grey = b_early[i]\n",
    "        b_latte     = b_late[i]\n",
    "\n",
    "        delta_r = [a_latte - a_earl_grey, b_latte - b_earl_grey]\n",
    "        vector_r = [0.5 * (a_latte + a_earl_grey), 0.5 * (b_latte + b_earl_grey)]\n",
    "\n",
    "        cross_z = delta_r[0] * vector_r[1] - delta_r[1] * vector_r[0]\n",
    "        dot_r = np.dot(vector_r, vector_r)\n",
    "\n",
    "        if dot_r == 0:\n",
    "            raise ZeroDivisionError(f\"change_in_phase_and_amp(): phase vector has zero magnitude at index {i}\")\n",
    "\n",
    "        rates_of_phases[i] = (1 / delta_t) * (cross_z / dot_r)\n",
    "        rates_of_amps[i]   = (1 / delta_t) * (np.dot(delta_r, vector_r) / dot_r)\n",
    "\n",
    "    return rates_of_phases, rates_of_amps\n",
    "\n",
    "\n",
    "def sharpness(second_derivatives, y_news):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `second_derivatives`: NumPy array of second derivatives\n",
    "    `y_news`: NumPy array of peak heights or values at the vertex of the parabola\n",
    "\n",
    "    ## Outputs:\n",
    "    NumPy array of sharpness values, defined as sqrt(-q / y)\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `y_news` and `second_derivatives` are same-length NumPy arrays\n",
    "    - Assumes `y_news` â‰  0 and `second_derivatives` < 0 (for real output)\n",
    "    \"\"\"\n",
    "\n",
    "    second_derivatives = np.asarray(second_derivatives)\n",
    "    y_news = np.asarray(y_news)\n",
    "    N = len(second_derivatives)\n",
    "\n",
    "    sharps = np.full(N, None)\n",
    "    for i in range(N):\n",
    "        if second_derivatives[i] is None or y_news[i] is None:\n",
    "            continue\n",
    "        sharps[i] = (-second_derivatives[i] / y_news[i]) ** 0.5\n",
    "\n",
    "    return sharps\n",
    "\n",
    "\n",
    "def null_chi_squared(ys, weights):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `ys`: numpy array of observed values (e.g., flux)  \n",
    "    `weights`: numpy array of weights corresponding to `ys`\n",
    "\n",
    "    ## Outputs:\n",
    "    `null_chisq`: weighted chi-squared value\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `ys` and `weights` are NumPy arrays of the same length\n",
    "    - Raises `ZeroDivisionError` if the sum of weights is zero \n",
    "    \"\"\"\n",
    "    total_weight = np.sum(weights)\n",
    "    if total_weight == 0:\n",
    "        raise ZeroDivisionError(\"null_chi_squared(): sum of weights is zero\")\n",
    "    \n",
    "    a0 = np.sum(weights * ys) / total_weight\n",
    "    null_chisq = np.sum(weights * (ys - a0) ** 2)\n",
    "    return np.array(null_chisq)\n",
    "\n",
    "def mask_vals(lc):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `lc`: Lightkurve LightCurve object containing:\n",
    "    - `lc.time.value`: time values (days)\n",
    "    - `lc.flux.value`: flux values\n",
    "    - `lc.flux_err.value`: flux uncertainties\n",
    "\n",
    "    ## Outputs:\n",
    "    3 NumPy arrays:\n",
    "    - `t_fit`: time values with valid (finite) data\n",
    "    - `flux_fit`: corresponding flux values\n",
    "    - `weight_fit`: corresponding weights (1 / sigma^2)\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `lc.time`, `lc.flux`, and `lc.flux_err` exist and have `.value` attributes\n",
    "    - No check for zero or negative `flux_err` (could produce invalid weights)\n",
    "    - Assumes all arrays are 1D and compatible in shape\n",
    "    \"\"\"\n",
    "\n",
    "    t_clean = np.ma.filled(lc.time.value, np.nan)\n",
    "    flux_clean = np.ma.filled(lc.flux.value, np.nan)\n",
    "    sigma_clean = np.ma.filled(lc.flux_err.value, np.nan)\n",
    "    mask = np.isfinite(t_clean) & np.isfinite(flux_clean) & np.isfinite(sigma_clean)\n",
    "\n",
    "    t_fit = t_clean[mask]\n",
    "    flux_fit = flux_clean[mask]\n",
    "    sigma_fit = sigma_clean[mask]\n",
    "    weight_fit = 1 / sigma_fit**2\n",
    "\n",
    "    return t_fit, flux_fit, weight_fit\n",
    "\n",
    "def pg_full(f_min, f_max, df, lc):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `f_min`: minimum frequency (float, 1/day) â€” sets frequency resolution  \n",
    "    `f_max`: maximum frequency (float, 1/day)  \n",
    "    `lc`: Lightkurve LightCurve object\n",
    "\n",
    "    ## Outputs:\n",
    "    Two NumPy arrays:\n",
    "    - `freq_full`: frequency grid (1/day)  \n",
    "    - `power_full`: corresponding Lomb-Scargle power spectrum values\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `f_min` > 0 and `f_max` > `f_min`\n",
    "    - No check for empty frequency grid if range is too small\n",
    "    - Assumes `lc.to_periodogram()` succeeds without errors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        frequency_grid_full = np.arange(f_min, f_max, df) / u.day\n",
    "        pg = lc.to_periodogram(\n",
    "            method='lombscargle',\n",
    "            normalization='psd',\n",
    "            frequency=frequency_grid_full\n",
    "        )\n",
    "        power_full = pg.power.value\n",
    "        freq_full = pg.frequency.to(1 / u.day).value\n",
    "        return freq_full, power_full\n",
    "    except Exception as e:\n",
    "        print(f\"pg_full(): Error during periodogram calculation: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def pg_mini(f_min, f_max, df, lc):\n",
    "    \"\"\"\n",
    "   \n",
    "    ## Inputs:\n",
    "    `f_min`: minimum frequency (float, 1/day)\n",
    "    `f_max`: maximum frequency (float, 1/day)  \n",
    "     #df is frequency spacing\n",
    "    `lc`: Lightkurve LightCurve object\n",
    "\n",
    "    ## Outputs:\n",
    "    Two NumPy arrays:\n",
    "    - `freq_mini`: frequency grid (1/day),  frequency range (up to `f_max/3`)  \n",
    "    - `power_mini`: corresponding Lomb-Scargle power spectrum values\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `f_min` > 0 and `f_max` > `f_min`\n",
    "    - No check for empty frequency grid if range is too small\n",
    "    - Assumes `lc.to_periodogram()` succeeds without errors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        frequency_grid_mini = np.arange(f_min, f_max / 3, df) / u.day\n",
    "        pg = lc.to_periodogram(\n",
    "            method='lombscargle',\n",
    "            normalization='psd',\n",
    "            frequency=frequency_grid_mini\n",
    "        )\n",
    "        power_mini = pg.power.value\n",
    "        freq_mini = pg.frequency.to(1 / u.day).value\n",
    "        return freq_mini, power_mini\n",
    "    except Exception as e:\n",
    "        print(f\"pg_mini(): Error during periodogram calculation: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def splitting(ts, K, jackknife = True):\n",
    "    '''\n",
    "    # splitting()\n",
    "    Produce either disjoint or jackknife subsamples.\n",
    "    \n",
    "    ## Inputs:\n",
    "    - `ts`: shape `(N, )` array of times (not necesarily ordered)\n",
    "    - `K`: number of subsamples to return\n",
    "    - `jackknife`: `True` for jackknife subsamples; otherwise disjoint\n",
    "    \n",
    "    ## Output: \n",
    "    - `masks`: shape `(K, N)` boolean array; `True` if in subsample\n",
    "\n",
    "    ## Comment:\n",
    "    - Relies on numpy conventions about relationships between integers and bools.\n",
    "    '''\n",
    "    N = len(ts)\n",
    "    indices = np.argsort(ts)\n",
    "    split_indices = np.array_split(indices, K)\n",
    "    if jackknife:\n",
    "        masks = np.ones((K, N), dtype=bool) # make everything True by default\n",
    "        for i, idx in enumerate(split_indices):\n",
    "            masks[i, idx] = False # remove subsample\n",
    "    else:\n",
    "        masks = np.zeros((K, N), dtype=bool) # make everything False by default\n",
    "        for i, idx in enumerate(split_indices):\n",
    "            masks[i, idx] = True # add subsample\n",
    "    return masks\n",
    "\n",
    "###FINAL COHERENCE TEST!!!!\n",
    "def coherence_all(ts, ys, weights, final_freq, T):\n",
    "\n",
    "    N = len(final_freq)\n",
    "    #oms = np.array([f * 2 * np.pi for f in final_freq])\n",
    "    all = np.full((N, 2), None)\n",
    "        \n",
    "\n",
    "    splits = np.array([2, 4, 8])\n",
    "    results = [np.full((N, n, 2), None) for n in splits]\n",
    "    \n",
    "    for idx, f in enumerate(final_freq):\n",
    "        if f is None:\n",
    "            continue\n",
    "        om = f * 2 * np.pi \n",
    "        A = integral_design_matrix(ts, om, T)\n",
    "        pars, _ = weighted_least_squares_new(A, ys, weights)\n",
    "        all[idx][0] = pars[1]\n",
    "        all[idx][1] = pars[2]\n",
    "\n",
    "    for split, result in zip(splits, results):     \n",
    "\n",
    "        jack = (split == 8)\n",
    "        masks = splitting(ts, split, jackknife = jack)\n",
    "        for idx, f in enumerate(final_freq):\n",
    "            if f is None:\n",
    "                continue\n",
    "            om = f * 2 * np.pi\n",
    "            for i, mask in enumerate(masks):\n",
    "                A = integral_design_matrix(ts[mask], om, T)\n",
    "                pars, _ = weighted_least_squares_new(A, ys[mask], weights[mask])\n",
    "                result[idx][i][0] = pars[1] #a\n",
    "                result[idx][i][1] = pars[2] #b\n",
    "\n",
    "    return all, results[0], results[1], results[2] #all, half, quarter, eighth (+jacknives)\n",
    "\n",
    "\n",
    "def sampling_stats(alls, quartiles, eighths):\n",
    "\n",
    "    f_num = len(alls)\n",
    "    \n",
    "    amp_change = np.full((f_num, 4), None)\n",
    "    phase_change = np.full((f_num, 4), None)\n",
    "\n",
    "    sigma_lnA = np.full(f_num, None)\n",
    "    sigma_phi4 = np.full(f_num, None)\n",
    "    sigma_phij = np.full(f_num, None)\n",
    "    \n",
    "    for inx, (all, quartile, eighth) in enumerate(zip(alls, quartiles, eighths)):\n",
    "\n",
    "        deltak_4 = np.zeros((4,2))\n",
    "        deltak_j = np.zeros((8,2))\n",
    "        a,b = all[0], all[1]\n",
    "        if a is None or b is None:\n",
    "            continue\n",
    "    \n",
    "        for i, q in enumerate(quartile):   \n",
    "            deltak_4[i] = [a - q[0], b - q[1]]\n",
    "\n",
    "        for i, j in enumerate(eighth):   \n",
    "            deltak_j[i] = [a - j[0], b - j[1]]\n",
    "                \n",
    "        x = np.array([a,b])\n",
    "        x_norm = np.linalg.norm([a, b])\n",
    "        x_hat = x / x_norm\n",
    "        y_hat = [x_hat[1], - x_hat[0]]\n",
    "\n",
    "        amp = np.dot(deltak_4, x_hat)/ x_norm\n",
    "        phase4 = np.dot(deltak_4, y_hat)/x_norm\n",
    "        phasej = np.dot(deltak_j, y_hat)/x_norm\n",
    "\n",
    "        var_lnA = 0.5 * np.sqrt(np.mean(amp ** 2))#1/2 rms lnA\n",
    "        varphi4 = 0.5 * np.sqrt(np.mean(phase4 ** 2)) #1/2 rms phase\n",
    "\n",
    "        varphij = np.sqrt((7/8) * np.sum(phasej ** 2)) #sigma phi\n",
    "\n",
    "        amp_change[inx] = amp\n",
    "        phase_change[inx] = phase4\n",
    "\n",
    "        sigma_lnA[inx] = var_lnA\n",
    "        sigma_phi4[inx] = varphi4\n",
    "        sigma_phij[inx] = varphij \n",
    "        \n",
    "        \n",
    "\n",
    "    return amp_change, phase_change, sigma_lnA, sigma_phi4, sigma_phij\n",
    "\n",
    "def star_search(kicID, plots = False, save = False, inject_rng = None, inject_amp = 0.01, max_peaks = 24):\n",
    "    \n",
    "    kicID = \"KIC\" + str(kicID).lstrip(\"0\")\n",
    "    \n",
    "\n",
    "    lc, delta_f, sampling_time, exptime = star(kicID)\n",
    "\n",
    "    if None in [lc]:\n",
    "        print(f\"Skipping {kicID} because star() returned None\")\n",
    "        return None\n",
    "\n",
    "    df, f_max, f_min = delta_f/3, (3 / (2*sampling_time)), 0.5 # magic number\n",
    "    t_fit, flux_fit, weight_fit = mask_vals(lc)\n",
    "    \n",
    "    inject = False\n",
    "    if inject_rng is not None:\n",
    "        inject = True\n",
    "        ain,bin = inject_amp * inject_rng.normal(size = 2)\n",
    "        fin = inject_rng.uniform(f_min, f_max)\n",
    "        inject_pars = (fin, ain, bin)\n",
    "        print(\"injection\", inject_pars)\n",
    "        flux_fit = inject_one_mode(t_fit, flux_fit, exptime, inject_pars)\n",
    "        lc = LightCurve(time=t_fit, flux=flux_fit) #setting new lc to match yin\n",
    "\n",
    "    freq_full, power_full = pg_full(f_min, f_max, df, lc)\n",
    "    freq_mini, power_mini = pg_mini(f_min, f_max, df, lc)\n",
    "\n",
    "    indices = get_filtered_peaks(max_peaks, freq_mini, power_mini)\n",
    "    refined_freq, refined_power, second_derivatives = refine_peaks(freq_mini, power_mini, indices)\n",
    "    fc = folding_freq(delta_f, freq_full, power_full, sampling_time, False)\n",
    "    regions, final_freqs, chi2s = region_and_freq(indices, fc, df, freq_mini, power_mini, t_fit, flux_fit, weight_fit, exptime)\n",
    "    nulls = null_chi_squared(flux_fit, weight_fit)\n",
    "    delta_chi2s = np.array([None if c is None else nulls - c for c in chi2s])\n",
    "\n",
    "    if np.any(delta_chi2s >= 100):\n",
    "        print(f\"delta_chi2s for {kicID}\", delta_chi2s)\n",
    "        #print(f\"exptime for {kicID} is {exptime}\")\n",
    "\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(\"No delta chi >= 100. skipping star\", kicID)\n",
    "        return  # or exit(), raise, etc.\n",
    "\n",
    "    sharpnesses = sharpness(second_derivatives, refined_power)\n",
    "\n",
    "    a_early, a_late, b_early, b_late = check_coherence(t_fit, flux_fit, weight_fit, final_freqs, exptime)\n",
    "    rate_of_phase, rate_of_amp = change_in_phase_and_amp(a_early, a_late, b_early, b_late, t_fit) #half\n",
    "    all, half, quartiles, eighths = coherence_all(t_fit, flux_fit, weight_fit, final_freqs, exptime)\n",
    "    amp_change, phase_change, sigma_lnA, sigma_phi4, sigma_phij = sampling_stats(all, quartiles, eighths)\n",
    "\n",
    "    if save:\n",
    "        date_str = datetime.now().strftime(\"%Y-%m-%d\") \n",
    "        output_dir = os.path.join(\"cool_kics_from_100\", f\"{date_str}_{kicID}\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        \n",
    "        data = Table()\n",
    "    \n",
    "    \n",
    "        data['Freqs'] = safe_arr(final_freqs)\n",
    "        data['Regions'] = safe_arr(regions)\n",
    "        data['Freq in region A'] = safe_arr(refined_freq)\n",
    "        #data['Sharp'] = safe_arr(sharpnesses)\n",
    "        data['Delta chi2'] = safe_arr(delta_chi2s)\n",
    "        #data['Change of phase(2)'] = safe_arr(rate_of_phase)\n",
    "        #data['Change of lnA(2)'] = safe_arr(rate_of_amp)\n",
    "        #data['Sigma lnA(4)'] = safe_arr(sigma_lnA)\n",
    "        data['Sigma phi(4)'] = safe_arr(sigma_phi4)\n",
    "        data['Sigma phi(jack)'] = safe_arr(sigma_phij)\n",
    "        \n",
    "        if inject:\n",
    "            ascii.write(\n",
    "            data,\n",
    "            kicID + '_injected_stats' + '.csv',\n",
    "            overwrite=True,\n",
    "            format=\"csv\",\n",
    "            formats={\n",
    "                \"Freqs\": \"{:.7f}\",\n",
    "                \"Freq in region A\": \"{:.7f}\",\n",
    "                #\"Sharp\": \"{:.7e}\",\n",
    "                \"Delta chi2\": \"{:.7e}\",\n",
    "                #\"Change of phase(2)\": \"{:.7e}\",\n",
    "                #\"Change of lnA(2)\": \"{:.7e}\",\n",
    "                #\"Sigma lnA(4)\": \"{:.7e}\",\n",
    "                \"Sigma phi(4)\": \"{:.7e}\",\n",
    "                \"Sigma phi(jack)\" : \"{:.7e}\"\n",
    "            }\n",
    "            )\n",
    "        else:\n",
    "            ascii.write(\n",
    "            data,\n",
    "            output = os.path.join(output_dir, kicID + '_stats.csv'),\n",
    "            overwrite=True,\n",
    "            format=\"csv\",\n",
    "            formats={\n",
    "                \"Freqs\": \"{:.7f}\",\n",
    "                \"Regions\": \"{}\",\n",
    "                \"Freq in region A\": \"{:.7f}\",\n",
    "                #\"Sharp\": \"{:.7e}\",\n",
    "                \"Delta chi2\": \"{:.7e}\",\n",
    "                #\"Change of phase(2)\": \"{:.7e}\",\n",
    "                #\"Change of lnA(2)\": \"{:.7e}\",\n",
    "                #\"Sigma lnA(4)\": \"{:.7e}\",\n",
    "                \"Sigma phi(4)\": \"{:.7e}\",\n",
    "                \"Sigma phi(jack)\" : \"{:.7e}\"\n",
    "            }\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    if plots:\n",
    "        #plot lightcurve\n",
    "        # if inject:\n",
    "        #     plt.plot(lc.time.value, lc.flux.value, color = \"k\", label = \"Injected Lightcurve\")\n",
    "        #     plt.xlabel(\"Time\")\n",
    "        #     plt.ylabel(\"Flux\")\n",
    "        #     plt.title(f\"Lightcurve of {kicID}\")\n",
    "        #     plt.show()\n",
    "        #     if save:\n",
    "        #         plt.savefig(os.path.join(output_dir, f\"{kicID}_injected_lightcurve.png\"))\n",
    "        # else:\n",
    "        #     plt.plot(lc.time.value, lc.flux.value, color = \"k\", label = \"Lightcurve\")\n",
    "        #     plt.xlabel(\"Time\")\n",
    "        #     plt.ylabel(\"Flux\")\n",
    "        #     plt.title(f\"Lightcurve of {kicID}\")\n",
    "        #     plt.show()\n",
    "        #     if save:\n",
    "        #         plt.savefig(os.path.join(output_dir, f\"{kicID}_lightcurve.png\"))\n",
    "\n",
    "\n",
    "        if inject:\n",
    "            plt.plot(freq_full, power_full, 'k.')\n",
    "            valid_points = [(f, p) for f, p in zip(final_freqs, refined_power) if f is not None and p is not None]\n",
    "            if valid_points:\n",
    "                valid_freqs, valid_power = zip(*valid_points)\n",
    "                plt.scatter(valid_freqs, valid_power, color='red', marker='o')\n",
    "            plt.scatter(final_freqs, refined_power, color = 'red', marker = 'o')\n",
    "            plt.xlabel(\"Frequency (1/day)\")\n",
    "            plt.ylabel(\"Power\")\n",
    "            plt.axvline(fc)\n",
    "            plt.axvline(fc/2)\n",
    "            plt.title(f\"Full Injected Periodogram of {kicID}\")\n",
    "            if save:\n",
    "                plt.savefig(os.path.join(output_dir, f\"{kicID}_injected_fullperio.png\"))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        else:\n",
    "            plt.plot(freq_full, power_full, 'k.')\n",
    "            valid_points = [(f, p) for f, p in zip(final_freqs, refined_power) if f is not None and p is not None]\n",
    "            if valid_points:\n",
    "                valid_freqs, valid_power = zip(*valid_points)\n",
    "                plt.scatter(valid_freqs, valid_power, color='red', marker='o')\n",
    "            plt.scatter(final_freqs, refined_power, color = 'red', marker = 'o')\n",
    "            plt.xlabel(\"Frequency (1/day)\")\n",
    "            plt.ylabel(\"Power\")\n",
    "            plt.axvline(fc)\n",
    "            plt.axvline(fc/2)\n",
    "            plt.title(f\"Full Periodogram of {kicID}\")\n",
    "            \n",
    "            if save:\n",
    "                plt.savefig(os.path.join(output_dir, f\"{kicID}_fullperio.png\"))\n",
    "            plt.show()\n",
    "\n",
    "        if inject:\n",
    "            plt.plot(freq_mini, power_mini, 'k.')\n",
    "            valid_points = [(f, p) for f, p in zip(final_freqs, refined_power) if f is not None and p is not None]\n",
    "            if valid_points:\n",
    "                valid_freqs, valid_power = zip(*valid_points)\n",
    "                #plt.scatter(valid_freqs, valid_power, color='red', marker='o')\n",
    "            #plt.scatter(final_freqs, refined_power, color = 'red', marker = 'o')\n",
    "            plt.xlabel(\"Frequency (1/day)\")\n",
    "            plt.ylabel(\"Power\")\n",
    "            #plt.axvline(fc)\n",
    "            #plt.axvline(fc/2)\n",
    "            plt.title(f\"Region A Injected Periodogram of {kicID}\")\n",
    "            if save:\n",
    "                plt.savefig(os.path.join(output_dir, f\"{kicID}_injected_miniperio.png\"))\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            plt.plot(freq_mini, power_mini, 'k.')\n",
    "            valid_points = [(f, p) for f, p in zip(final_freqs, refined_power) if f is not None and p is not None]\n",
    "            if valid_points:\n",
    "                valid_freqs, valid_power = zip(*valid_points)\n",
    "                #plt.scatter(valid_freqs, valid_power, color='red', marker='o')\n",
    "            plt.xlabel(\"Frequency (1/day)\")\n",
    "            plt.ylabel(\"Power\")\n",
    "            #plt.axvline(fc)\n",
    "            #plt.axvline(fc/2)\n",
    "            plt.title(f\"Region A  Periodogram of {kicID}\")\n",
    "            \n",
    "            if save:\n",
    "                plt.savefig(os.path.join(output_dir, f\"{kicID}_miniperio.png\"))\n",
    "            plt.show()\n",
    "\n",
    "        if inject:\n",
    "            plt.plot(freq_mini, power_mini, 'k-')\n",
    "            plt.xlabel(\"Frequency (1/day)\")\n",
    "            plt.ylabel(\"Log Power\")\n",
    "            plt.semilogy()\n",
    "            plt.title(f\"Region A Log Injected Periodogram of {kicID}\")\n",
    "            \n",
    "            if save:\n",
    "                plt.savefig(os.path.join(output_dir, f\"{kicID}_injected_mini_logperio.png\"))\n",
    "            plt.show()\n",
    "        else:\n",
    "\n",
    "            plt.plot(freq_mini, power_mini, 'k-')\n",
    "            plt.xlabel(\"Frequency (1/day)\")\n",
    "            plt.ylabel(\"Log Power\")\n",
    "            plt.semilogy()\n",
    "            plt.title(f\"Region A Log Periodogram of {kicID}\")\n",
    "            \n",
    "            if save:\n",
    "                plt.savefig(os.path.join(output_dir, f\"{kicID}_mini_logperio.png\"))\n",
    "            plt.show()\n",
    "        \n",
    "        #fc = folding_freq(delta_f, freq_full, power_full, sampling_time, True)\n",
    "\n",
    "        #15 point graph\n",
    "        fig, axes = plt.subplots(3, 4, figsize=(16, 9))\n",
    "        plt.suptitle(f\"15 Point figure of {kicID}\", fontsize = 18)\n",
    "        \n",
    "        for idx, (ax, points1, points2, points3, points4, p1, p2, p3, p4) in enumerate(zip(axes.flat, all, half, quartiles, eighths, rate_of_phase, \n",
    "                                                                                           sigma_phi4, sigma_phij, phase_change)):\n",
    "            if points1 is None or points2 is None or points3 is None or points4 is None:\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                a_all = points1[0]\n",
    "                b_all = points1[1]\n",
    "        \n",
    "                a_half = [row[0] for row in points2 if row[0] is not None and row[1] is not None]\n",
    "                b_half = [row[1] for row in points2 if row[0] is not None and row[1] is not None]\n",
    "        \n",
    "                a_quarter = [row[0] for row in points3 if row[0] is not None and row[1] is not None]\n",
    "                b_quarter = [row[1] for row in points3 if row[0] is not None and row[1] is not None]\n",
    "        \n",
    "                a_eighth = [row[0] for row in points4 if row[0] is not None and row[1] is not None]\n",
    "                b_eighth = [row[1] for row in points4 if row[0] is not None and row[1] is not None]\n",
    "        \n",
    "                ax.scatter(a_half, b_half, color='orange', marker='*')\n",
    "                ax.scatter(a_quarter, b_quarter, color='blue', marker='+')\n",
    "                ax.scatter(a_eighth, b_eighth, color='k', marker='.')\n",
    "                ax.scatter(a_all, b_all, color='red', marker='x')\n",
    "        \n",
    "                p1_str = f\"{p1:0.8e}\" if p1 is not None else \"None\"\n",
    "                p2_str = f\"{p2:0.8e}\" if p2 is not None else \"None\"\n",
    "                p3_str = f\"{p3:0.8e}\" if p3 is not None else \"None\"\n",
    "        \n",
    "                ax.text(0.05, 0.95, f\"phase change(2): {p1_str}\", transform=ax.transAxes,\n",
    "                        fontsize=8, verticalalignment='top', color='green')\n",
    "                ax.text(0.05, 0.88, f\"sigma phi(4): {p2_str}\", transform=ax.transAxes,\n",
    "                        fontsize=8, verticalalignment='top', color='green')\n",
    "                ax.text(0.05, 0.81, f\"sigma phi(jack): {p3_str}\", transform=ax.transAxes,\n",
    "                        fontsize=8, verticalalignment='top', color='green')\n",
    "        \n",
    "                freq_label = f\"{final_freqs[idx]:0.8f}\" if final_freqs[idx] is not None else \"None\"\n",
    "                ax.set_title(freq_label)\n",
    "        \n",
    "                ax.axvline(0, color='k')\n",
    "                ax.axhline(0, color='k')\n",
    "                ax.set_xlabel(\"a points\")\n",
    "                ax.set_ylabel(\"b points\")\n",
    "                ax.grid(True)\n",
    "                ax.ticklabel_format(style='sci', scilimits=(-3, 3), axis='both')\n",
    "                ax.axis('equal')\n",
    "                \n",
    "        \n",
    "            except Exception as e:\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "\n",
    "        if inject:\n",
    "            if save:\n",
    "                plt.savefig(os.path.join(output_dir, f\"{kicID}_injected_15point.png\"))\n",
    "            plt.show()\n",
    "        else:\n",
    "            if save:\n",
    "                plt.savefig(os.path.join(output_dir, f\"{kicID}_15point.png\"))\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d750e0d-2508-4397-bd8a-fd780b33d3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
