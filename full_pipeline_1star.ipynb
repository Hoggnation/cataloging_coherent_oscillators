{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e6f06-3d48-4df0-af48-7e3548b08837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import scipy.signal\n",
    "from astropy import units as u\n",
    "import nana\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.patches import Ellipse\n",
    "from math import cos, sin, radians\n",
    "from matplotlib.collections import EllipseCollection\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec242bc-df3c-4bd2-bf04-4b0551810edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_started(num_of_peaks, xs, ys): \n",
    "    \"\"\"\n",
    "    \n",
    "    Identifies and returns the indices of the highest peaks in a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        num_of_peaks (int): The number of highest peaks to return.\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "\n",
    "    Returns:\n",
    "        numpy array: An array of indices corresponding to the highest peaks in `ys`.\n",
    "\n",
    "    Bugs:\n",
    "        `num_of_peaks` cannot be greater than the number of detected peaks\n",
    "        `xs` or `ys` must be NumPy array\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    indxs, properties = find_peaks(ys)\n",
    "    return indxs[np.argsort(-ys[indxs])[:num_of_peaks]]\n",
    "\n",
    "def check_inputs(xs):\n",
    "    \"\"\"\n",
    "    \n",
    "    Checks whether the input array `xs` is sorted in ascending order.\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray or list): The input array to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: `True` if `xs` is sorted in ascending order, otherwise `False`.\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(len(xs)-1):\n",
    "        if xs[i] > xs[i+1]:\n",
    "            print(\"check_inputs(): input xs is badly ordered. Use reorder_inputs to reorder\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def reorder_inputs(xs,ys):\n",
    "    \"\"\"\n",
    "    \n",
    "    Reorders the input arrays `xs` and `ys` in ascending order of `xs`.\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "        \n",
    "    Returns:\n",
    "        tuple of numpy arrays (sorted xs, sorted ys)\n",
    "\n",
    "    Bugs:\n",
    "        `xs` or `ys` must be NumPy array\n",
    "        `xs` and `ys`must be same length\n",
    "        \n",
    "    \"\"\"\n",
    "    i = np.argsort(xs)\n",
    "    return xs[i], ys[i]\n",
    "\n",
    "#xlist is the teh index left to highest peak, highest peak, and the index right to teh highest peak\n",
    "def design_matrix(xlist): \n",
    "    \"\"\"\n",
    "    \n",
    "    Constructs a design matrix for quadratic curve fitting.\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "\n",
    "    Returns:\n",
    "        3 x 3 design matrix of numpy arrays\n",
    "\n",
    "    Bugs:\n",
    "        xlist must be an numpy array\n",
    "\n",
    "    Note:\n",
    "        Note the factor of 0.5 that Hogg likes and no one else\n",
    "        Also assumes xlist is ordered\n",
    "    \n",
    "    \"\"\"\n",
    "    return (np.vstack((xlist**0,xlist**1,0.5*xlist**2))).T\n",
    "\n",
    "def fit_parabola(xs, ys, index):\n",
    "    \"\"\"\n",
    "\n",
    "    Fits a quadratic function to three consecutive data points. Solves for coefficients (b,m,q) in the quadratic\n",
    "    f(x) = b + m*x + (1/2) * q * x^2\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "        index (int): The index of peak\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        tuple: (b, m, q)\n",
    "\n",
    "    Bugs: \n",
    "        index-1` or `index+2` can't be out of bounds\n",
    "        ``xs` or `ys` must be NumPy array\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    return np.linalg.solve(design_matrix(xs[index-1:index+2]), ys[index-1:index+2])\n",
    "\n",
    "def refine_peak(xs, ys, index):\n",
    "    \"\"\"\n",
    "\n",
    "    Refines the peak position using quadratic fit\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "        index (int): The index of peak\n",
    "    \n",
    "    Returns:\n",
    "        3-tuple: (x position of refined peak, y position of refined peak, and second derivative (q))\n",
    "\n",
    "    Bugs:\n",
    "        Must be synchronized with the design matrix\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    b,m,q = fit_parabola(xs, ys, index)\n",
    "    x_peak = -m / q\n",
    "    return x_peak, 0.5 * q * (x_peak) ** 2 + m * (x_peak) + b, q\n",
    "    \n",
    "def refine_peaks(xs, ys, indices):\n",
    "    \"\"\"\n",
    "\n",
    "    Refines the peak position for a set of indices using quadratic fit\n",
    "\n",
    "    Args:\n",
    "        xs (numpy.ndarray): The x-axis values \n",
    "        ys (numpy.ndarray): The y-axis values\n",
    "        indices (numpy array): indices of the peaks (this should be the output of get_started()\n",
    "\n",
    "    Returns:\n",
    "        three  numpy arrays (array of refined x positions, array of refined y positions, and the second derivatives)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    foo = lambda i: refine_peak(xs,ys,i)\n",
    "    xs_refined, ys_refined, second_derivatives = zip(*list(map(foo,indices)))\n",
    "    return np.array(xs_refined), np.array(ys_refined), np.array(second_derivatives)\n",
    "\n",
    "\n",
    "def folding_freq(fs, ps, sampling_time, makeplots=False):\n",
    "    \"\"\"\n",
    "    ##bugs:\n",
    "    - assumes fs are ordered\n",
    "    - global delta_f\n",
    "    \"\"\"\n",
    "    fc_guess = 1. / sampling_time\n",
    "    \n",
    "    IA = fs < 0.5 * fc_guess\n",
    "    fsA, psA = fs[IA], ps[IA]\n",
    "    fsA,psA  = fsA[2:-2],  psA[2:-2]\n",
    "    cs = CubicSpline(fs, ps, extrapolate=False)\n",
    "    \n",
    "    small, tiny = 20 * delta_f, 0.25 * delta_f\n",
    "    fc_candidates = np.arange(fc_guess - small, fc_guess + small, tiny)\n",
    "    foos_c = np.array([np.nansum(psA * cs(fc - fsA)) for fc in fc_candidates])\n",
    "    fc_index = get_started(1,fc_candidates, foos_c)\n",
    "    fc, _, _ = refine_peaks(fc_candidates, foos_c, fc_index)\n",
    "    fc = fc[0]\n",
    "    \n",
    "    if makeplots:\n",
    "        plt.plot(fc_candidates, foos_c)\n",
    "        plt.axvline(fc_guess)\n",
    "        plt.axvline(fc, color = 'red', alpha = 0.5)\n",
    "        plt.title(fc)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    return fc\n",
    "\n",
    "def find_min_and_refine(xs,ys):\n",
    "    indxs, properties = find_peaks(-ys)\n",
    "    min_index =  indxs[np.argsort(ys[indxs])[:1]]\n",
    "    refined_x, refined_y, second_derivative = refine_peaks(xs, ys, min_index)\n",
    "    return refined_x[0], refined_y[0]\n",
    "\n",
    "def get_started_filtered(num_of_peaks, xs, ys): \n",
    "    '''\n",
    "    ##bugs:\n",
    "    - realizes on global variable f_avoid\n",
    "    '''\n",
    "    indxs, properties = find_peaks(ys)\n",
    "    indices = indxs[np.argsort(-ys[indxs])]\n",
    "\n",
    "    filtered = []\n",
    "    for index in indices:\n",
    "        if all(abs(xs[index] - xs[i]) >= (f_avoid) for i in filtered):\n",
    "            filtered.append(index)\n",
    "            if(len(filtered) >= num_of_peaks):\n",
    "                break\n",
    "    return np.array(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3005b821-6d50-4f37-8f9c-dfb45de29b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = lk.search_lightcurve('KIC 5202905', mission='Kepler')\n",
    "lc_collection = search_result.download_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8546ae-66c5-4a4a-a96c-dbb955e39f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lc_collection.stitch()\n",
    "total_observation_time = (lc.time[-1] - lc.time[0]).value\n",
    "delta_f = (1/total_observation_time) \n",
    "sampling_time= np.median(np.diff(lc.time.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cfec24-9ac2-4be9-a499-7bc91ab53c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a magic number\n",
    "f_avoid = 3.5 / 372.5 #372.5 is kepler orbital period, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f22eee-8469-4296-bdc0-d8e2664077a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_max = (2 / (sampling_time))\n",
    "f_min = delta_f/3\n",
    "frequency_grid_full = np.arange(f_min, f_max, f_min)/(u.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f026f25-70a1-4789-bb1a-5b0936cd4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_full = lc.to_periodogram(\n",
    "    method='lombscargle',\n",
    "    normalization='psd',\n",
    "    frequency=frequency_grid_full\n",
    ")\n",
    "\n",
    "power_full = pg_full.power.value\n",
    "freq_full = pg_full.frequency.to(1/u.day).value \n",
    "\n",
    "plt.plot(freq_full, power_full,'k.')\n",
    "plt.plot(freq_full, power_full,'k-', lw = 0.5, alpha = 0.5)\n",
    "plt.xlabel(\"Frequency (1/day)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(\"Lomb-Scargle Periodogram of KIC 5202905\")\n",
    "plt.axvline(1/sampling_time)\n",
    "plt.axvline(1/(2*sampling_time))\n",
    "plt.axvline(3/(2*sampling_time))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016ef21-101c-4823-a8db-b128eb3f44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_grid = np.arange(f_min, f_max / 4, f_min) / (u.day)\n",
    "\n",
    "pg = lc.to_periodogram(\n",
    "    method='lombscargle',\n",
    "    normalization='psd',\n",
    "    frequency=frequency_grid\n",
    ")\n",
    "\n",
    "power = pg.power.value\n",
    "freq = pg.frequency.to(1/u.day).value \n",
    "\n",
    "plt.plot(freq, power, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb0252-d93c-4828-98f5-810642740eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lc.time.value\n",
    "flux = lc.flux.value\n",
    "sigma = lc.flux_err.value\n",
    "\n",
    "t_clean = np.ma.filled(t, np.nan)\n",
    "flux_clean = np.ma.filled(flux, np.nan)\n",
    "sigma_clean = np.ma.filled(sigma, np.nan)\n",
    "\n",
    "mask = np.isfinite(t_clean) & np.isfinite(flux_clean) & np.isfinite(sigma_clean)\n",
    "\n",
    "lc = lc[mask]\n",
    "t_fit = t_clean[mask]\n",
    "flux_fit = flux_clean[mask]\n",
    "sigma_fit = sigma_clean[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647de1e-1d68-4363-ac7a-c3b5f378dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_exptime = (6.52 * 270) / (60 * 60 * 24) #days, see Kepler Data Processing Handbook, Section 3.1\n",
    "weight_fit = 1 / sigma_fit**2\n",
    "\n",
    "def integral_design_matrix(ts, om, T):\n",
    "    \"\"\"\n",
    "    ##bugs:\n",
    "    - assumes all data points have the same exposure time, `T`\n",
    "    - not numerically stable when `om * T` is small\n",
    "    \"\"\"\n",
    "    return np.vstack([\n",
    "        np.ones_like(ts),\n",
    "        (+ np.sin(om * (ts + T/2)) - np.sin(om * (ts - T/2))) / (om * T),\n",
    "        (- np.cos(om * (ts + T/2)) + np.cos(om * (ts - T/2))) / (om * T)\n",
    "    ]).T\n",
    "\n",
    "def weighted_least_squares(A, b, weights):\n",
    "    ATA = A.T @ (A * weights[:, np.newaxis])\n",
    "    ATb = A.T @ (b * weights)\n",
    "    return A @ np.linalg.solve(ATA, ATb)\n",
    "\n",
    "def weighted_least_squares_new(A, b, weights):\n",
    "    ATA = A.T @ (A * weights[:, np.newaxis])\n",
    "    ATb = A.T @ (b * weights)\n",
    "    trace = np.trace(ATA)\n",
    "    det = np.linalg.det(ATA)\n",
    "    return np.linalg.solve(ATA, ATb), ATA\n",
    "\n",
    "def integral_chi_squared(om, ts, ys, ws, T):\n",
    "    A = integral_design_matrix(ts, om, T)\n",
    "    return np.sum(ws * (ys - weighted_least_squares(A, ys, ws))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e339ad-1ae8-4bb1-9006-6f3ec8b89778",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = folding_freq(freq_full, power_full, sampling_time, False)\n",
    "indices = get_started_filtered(12, freq, power)\n",
    "refined_freq, refined_power, second_derivatives = refine_peaks(freq, power, indices)\n",
    "print(refined_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cd88c-394a-46ab-a0d3-696a09e52300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the correponding A,B,C region for each peak\n",
    "#finding which region the peak truly lies in\n",
    "#output bestchisquared\n",
    "#use np.likzeros\n",
    "#look over a,b,c loop over dictionary, similar to cases, dictionary with three elements\n",
    "def region_and_freq(indices, folding_freq):\n",
    "    \n",
    "    regions, best_freqs, best_chi2s = [], [], []\n",
    "\n",
    "    for i in range(len(indices)):\n",
    "        fas, __, __ = refine_peaks(freq, power, indices)\n",
    "        A, B, C = fas, folding_freq-fas, folding_freq+fas\n",
    "        \n",
    "        fine_freqsA = np.arange(A[i] - 5 * f_min, A[i] + 5 * f_min, 0.2 * f_min)  \n",
    "        chi2_fineA = np.array([integral_chi_squared(2. * np.pi * f, t_fit, flux_fit, weight_fit, lc_exptime) for f in fine_freqsA])\n",
    "        best_freqA, best_chi2A = find_min_and_refine(fine_freqsA,chi2_fineA)\n",
    "    \n",
    "        fine_freqsB = np.arange(B[i]- 5 * f_min, B[i] + 5 * f_min, 0.2 * f_min)  \n",
    "        chi2_fineB = np.array([integral_chi_squared(2. * np.pi * f, t_fit, flux_fit, weight_fit, lc_exptime) for f in fine_freqsB])\n",
    "        best_freqB, best_chi2B = find_min_and_refine(fine_freqsB,chi2_fineB)\n",
    "    \n",
    "        fine_freqsC = np.arange(C[i] - 5 * f_min, C[i] + 5 * f_min, 0.2 * f_min)  \n",
    "        chi2_fineC = np.array([integral_chi_squared(2. * np.pi * f, t_fit, flux_fit, weight_fit, lc_exptime) for f in fine_freqsC])\n",
    "        best_freqC, best_chi2C = find_min_and_refine(fine_freqsC,chi2_fineC)\n",
    "        \n",
    "        #print(best_chi2A, best_chi2B, best_chi2C)\n",
    "\n",
    "        if (best_chi2A <= best_chi2B and best_chi2A <= best_chi2C):\n",
    "            regions.append(\"A\")\n",
    "            best_freqs.append(best_freqA)\n",
    "            best_chi2s.append(best_chi2A)\n",
    "            \n",
    "        elif (best_chi2B < best_chi2A and best_chi2B < best_chi2C):\n",
    "            #print(\"here\")\n",
    "            regions.append(\"B\")\n",
    "            best_freqs.append(best_freqB)\n",
    "            best_chi2s.append(best_chi2B)\n",
    "            \n",
    "        elif (best_chi2C < best_chi2A and best_chi2C < best_chi2B):\n",
    "            #print(\"herec\")\n",
    "            regions.append(\"C\")\n",
    "            best_freqs.append(best_freqC)\n",
    "            best_chi2s.append(best_chi2C)\n",
    "\n",
    "\n",
    "    return(regions, best_freqs, best_chi2s)\n",
    "\n",
    "regions, freqs, chi2s = region_and_freq(indices, fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935b2e8-cf10-4b40-ad26-f2d9ad356da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coherence(ts, ys, weights, oms):\n",
    "    '''assumes a lot of thing about the data\n",
    "    '''\n",
    "\n",
    "    \n",
    "    a_early, a_late, b_early, b_late, invvars = [], [], [], [], []\n",
    "    \n",
    "    ts_median = np.median(ts)\n",
    "    \n",
    "    cases = [(ts < ts_median, \"early\"),\n",
    "             (ts > ts_median, \"late\")]\n",
    "    \n",
    "    for om in oms:\n",
    "        \n",
    "        for I, name in cases:\n",
    "            A = integral_design_matrix(ts[I], om, lc_exptime)\n",
    "            pars, ___ = weighted_least_squares_new(A, ys[I], weights[I])\n",
    "            a,b = pars[1], pars[2]\n",
    "            \n",
    "            if name == \"early\":\n",
    "                a_early.append(pars[1])\n",
    "                b_early.append(pars[2])\n",
    "            elif name == \"late\":\n",
    "                a_late.append(pars[1])\n",
    "                b_late.append(pars[2])\n",
    "\n",
    "    return a_early, a_late, b_early, b_late\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c03e9-f600-42e0-97c1-cc4d4b0d4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oms = np.array([(f * 2 * np.pi) for f in freqs])\n",
    "\n",
    "a_early, a_late, b_early, b_late = check_coherence(t_fit, flux_fit, weight_fit, oms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdcb1ae-386d-407e-b379-1bbcad9908af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_in_phase_and_amp(a_early, a_late, b_early, b_late, ts):\n",
    "\n",
    "    rates_of_phases = []\n",
    "    rates_of_amps = []\n",
    "    ts_median = np.median(ts)\n",
    "    delta_t = np.median(ts[ts>ts_median]) - np.median(ts[ts < ts_median])\n",
    "\n",
    "    \n",
    "\n",
    "    for a_earl_grey, a_latte, b_earl_grey, b_latte in zip(a_early, a_late, b_early, b_late):\n",
    "    \n",
    "\n",
    "        delta_r = [a_latte - a_earl_grey, b_latte - b_earl_grey]\n",
    "        vector_r = [0.5 * (a_latte + a_earl_grey), 0.5 * (b_latte + b_earl_grey)]\n",
    "\n",
    "        cross_z = delta_r[0] * vector_r[1] - delta_r[1] * vector_r[0]\n",
    "        phase = (1 / delta_t) * (cross_z / np.dot(vector_r, vector_r))\n",
    "        rates_of_phases.append(phase)\n",
    "        \n",
    "        amplitude = (1/(delta_t)) * (np.dot(delta_r, vector_r) / np.dot(vector_r, vector_r))\n",
    "        rates_of_amps.append(amplitude)\n",
    "\n",
    "    return (rates_of_phases, rates_of_amps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9896911-4bc7-4430-80f0-98c4807e9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_rate_of_phase, F2_rate_of_amp = change_in_phase_and_amp(a_early, a_late, b_early, b_late, t_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec1d02-112f-439a-b32f-59b6676ab428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics to give hogg for each freq\n",
    "#the freq, the region\n",
    "#the corresponding frequency in region \"A\"\n",
    "#t, F1 values\n",
    "print(\"These are top 12 frequecies:\", freqs)\n",
    "print(\"These are the regions:\", regions)\n",
    "print(\"Correspoding freq in a regions:\", freq)\n",
    "print(\"rate of chaneg of phases:\", F1_rate_of_phase)\n",
    "print(\"rate of change of amplitudes\", F2_rate_of_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bd035-11e4-48d7-b28d-871994990383",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(freq))\n",
    "print(len(freq))\n",
    "#print(len(refined_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d6ef2-6ee3-4932-98f1-88a1f5465550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = Table()\n",
    "'''\n",
    "data['top_12_freqs'] = freqs\n",
    "data['regions'] = regions\n",
    "data['corresponding_freq_in_region_A'] = refined_freq\n",
    "data['rate_of_change_of_phase'] = F1_rate_of_phase\n",
    "data['rate_of_change_of_amplitude'] = F2_rate_of_amp\n",
    "\n",
    "# Write to CSV with custom formatting\n",
    "ascii.write(\n",
    "    data,\n",
    "    'top12_in_KIC_5202905.csv',\n",
    "    overwrite=True,\n",
    "    format=\"csv\",\n",
    "    formats={\n",
    "        \"top_12_freqs\": \"{:.10f}\",\n",
    "        \"corresponding_freq_in_region_A\": \"{:.10f}\",\n",
    "        \"rate_of_change_of_phase\": \"{:.5e}\",\n",
    "        \"rate_of_change_of_amplitude\": \"{:.5e}\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(type(freqs))# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8837d-eb37-4a80-b496-9e54bbb5f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delta_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a14dd5-8a1f-459a-81b9-4acbfb75df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_rate_of_phase = np.abs(F1_rate_of_phase)\n",
    "F2_rate_of_amp = np.abs(F2_rate_of_amp)\n",
    "\n",
    "\n",
    "# Plot 1: F1_rate_of_phase vs F2_rate_of_amp, color by freqs\n",
    "plt.figure()\n",
    "plt.scatter(F1_rate_of_phase, F2_rate_of_amp, c=freqs, cmap='viridis')\n",
    "plt.xlabel(\"rate of change of phase\")\n",
    "plt.ylabel(\"rate of change of amplitude\")\n",
    "plt.title(\"Color: frequencies\")\n",
    "plt.colorbar(label=\"frequency range\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: F1_rate_of_phase vs freqs, color by F2_rate_of_amp\n",
    "plt.figure()\n",
    "plt.scatter(F1_rate_of_phase, freqs, c=F2_rate_of_amp, cmap='plasma')\n",
    "plt.xlabel(\"rate of change of phase\")\n",
    "plt.ylabel(\"frequenices\")\n",
    "plt.title(\"Color: rate of change of amplitude\")\n",
    "plt.colorbar(label=\"rate of change of amplitude range\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: F2_rate_of_amp vs freqs, color by F1_rate_of_phase\n",
    "plt.figure()\n",
    "plt.scatter(F2_rate_of_amp, freqs, c=F1_rate_of_phase, cmap='summer')\n",
    "plt.xlabel(\"rate of change of amplitude\")\n",
    "plt.ylabel(\"frequencies\")\n",
    "plt.title(\"Color: rate of change of phase\")\n",
    "plt.colorbar(label=\"rate of change of phase range\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c092df-aa38-4aff-99b0-59591521d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpness(second_derivatives, y_news):\n",
    "    sharps = []\n",
    "    for second_derivative, y_new in zip(second_derivatives, y_news):\n",
    "        sharpness = (-second_derivative/y_new)**(1/2)\n",
    "        sharps.append(sharpness)\n",
    "    return sharps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7dd718-a1be-4d96-9fd4-31ed2d25d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpnesses = sharpness(second_derivatives, refined_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355decdc-46b6-4d58-9c6f-ddd74f4e8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(sharpnesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614f15f-ab3b-46a4-a8bf-c2c70aeba2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sharpness\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(F1_rate_of_phase, freqs, c=sharpnesses, cmap='copper')\n",
    "plt.xlabel(\"rate of change of phase range\")\n",
    "plt.ylabel(\"frequencies\")\n",
    "plt.title(\"Color: sharpness\")\n",
    "plt.colorbar(label=\"sharpness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e8158-66f9-4d33-9336-e79be3273ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([freqs, F1_rate_of_phase, F2_rate_of_amp, sharpnesses])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a81a94-0db9-4e2e-b17e-5ad843792b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute delta-chi-squared for each mode\n",
    "\n",
    "#instructions from hogg\n",
    "#a0 = np.sum(invvar * flux) / np.sum(invvar)\n",
    "#ull_chisq = np.sum(invvar * (flux - a0) ** 2)\n",
    "#And then you subtract from this the best chisq at the best refined frequency.\n",
    "\n",
    "def null_chi_squared(ts, ys, weights):\n",
    "    \n",
    "    a0 = np.sum(weights * ys) / np.sum(weights)\n",
    "    null_chisq = np.sum(weights * (ys - a0) ** 2)\n",
    "    return null_chisq\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637538c6-c9bc-4f4f-ae12-4d24d389db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_chi2s = null_chi_squared(t_fit, flux_fit, weight_fit) - chi2s\n",
    "print(delta_chi2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b4450-ea2b-48d2-b450-4e33a712240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###new stats to send to hogg\n",
    "##the chisquared refined frequencies\n",
    "##the region\n",
    "##corresponding frequency in region A\n",
    "##sharpness\n",
    "##delta chi squared\n",
    "##the F1 value rate of change of phase, dphi/dt\n",
    "##the F2 value, rate of change of amplitude, dA/dt\n",
    "\n",
    "chi_squared_refined_freqs = freqs\n",
    "regions =regions\n",
    "freqs_in_A = refined_freq\n",
    "sharpnesses = sharpnesses\n",
    "dphi_dt = F1_rate_of_phase\n",
    "dA_dt = F2_rate_of_amp\n",
    "\n",
    "data = Table()\n",
    "\n",
    "\n",
    "data['modes'] = freqs\n",
    "data['regions'] = regions\n",
    "data['corresponding_freq_in_region_A'] = refined_freq\n",
    "data['sharpness'] = sharpnesses\n",
    "data['delta_chi_squares'] = delta_chi2s\n",
    "data['rate_of_change_of_phase'] = dphi_dt\n",
    "data['rate_of_change_of_amplitude'] = dA_dt\n",
    "\n",
    "# Write to CSV with custom formatting\n",
    "ascii.write(\n",
    "    data,\n",
    "    'new_stats_for_KIC_5202905.csv',\n",
    "    overwrite=True,\n",
    "    format=\"csv\",\n",
    "    formats={\n",
    "        \"modes\": \"{:.10f}\",\n",
    "        \"corresponding_freq_in_region_A\": \"{:.5f}\",\n",
    "        \"sharpness\": \"{:.7e}\",\n",
    "        \"delta_chi_squares\": \"{:.7e}\",\n",
    "        \"rate_of_change_of_phase\": \"{:.7e}\",\n",
    "        \"rate_of_change_of_amplitude\": \"{:.7e}\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39816d-5e9f-4e25-82b3-1fb91b1804f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c48e2-388e-4051-a109-177779d3fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freq, power, 'k.')\n",
    "plt.scatter(refined_freq, power[indices], color='r', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d98250-1182-4f73-84e8-f2bf35f71496",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freq[indices], power[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2e3f4-90c7-413a-9733-c857d5fd7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freq_full, power_full, 'k-')\n",
    "plt.scatter(freqs, refined_power, color='r', marker='o')\n",
    "#plt.xlim(38.392, 38.44)\n",
    "plt.xlim(59.44, 59.52)\n",
    "plt.axvline(59.48)\n",
    "plt.axvline(59.48 + 1 / 372.5)\n",
    "#plt.xlim(24.469500173919045, 48.93900034783809)\n",
    "#plt.xlim(48.93900034783809, 73.40850052175713)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd408d6-28f4-4904-b99d-c0b485fecc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e8f5d-cf26-4892-8239-9cbbed1b2183",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3/(2*sampling_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7360365-ba7a-464f-abd9-9c04a1f2bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1/sampling_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e77576-ce91-48a2-b5bd-26bbd4ea9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refined_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbdeb8b-1281-4f1e-bf1f-288a4c0629e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941994a-a918-4456-940a-5c6170f8abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e602a-237b-4273-a73e-aa82618f1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freqs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a159a50-19d8-4368-a1fa-21fdced64c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refined_freq[0], refined_freq[6])\n",
    "freqs_check = [refined_freq[0], refined_freq[6]]\n",
    "powers_check = [refined_power[0], refined_power[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0292e8-a4fc-46b6-b0a1-48550c869ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freq, power, 'k-')\n",
    "#plt.xlim(10.52, 10.56)\n",
    "plt.scatter(refined_freq, refined_power, color='r', marker='o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ac85f-96e8-4014-a61a-57512e203ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(power[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098d512-4f9b-4829-b772-34e492c1a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d7e73-588a-49a0-95ec-0a23b86b33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19318a-1363-462e-bba4-48ded711813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs[0]-freqs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cfa4b0-f83b-4f45-baef-585a9bb77b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pipeline we're trying now\n",
    "#find 12 peaks im region A\n",
    "#for each peak use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec398e-0280-47ea-9f11-70f53df959d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = get_started_filtered(12, freq, power)\n",
    "\n",
    "plt.plot(freq, power, 'k-')\n",
    "#plt.xlim(24, 24.2)\n",
    "#plt.ylim(-1e-8, 2e-7)\n",
    "plt.scatter(freq[filters], power[filters], color = 'r', marker = 'o')\n",
    "print(len(filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8ac88-4697-4ba2-825a-b8271da03329",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refined_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf3be5-6d12-45b7-bd42-f20397ac1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(refined_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c009d4-e896-4f3f-a759-bfe7e876da74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
