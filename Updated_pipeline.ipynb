{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fda52e-a561-4e3a-8958-1626e8b77f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from astropy.table import Table\n",
    "from scipy.interpolate import CubicSpline\n",
    "from datetime import datetime\n",
    "import os\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "from lightkurve import LightCurve\n",
    "from lightkurve import LightkurveError\n",
    "import time\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "f_avoid = 3.5 / 372.5 #magic number\n",
    "lc_exptime = (29.4) / (60 * 24) #days, see Kepler Data Processing Handbook, Section 3.1\n",
    "sc_exptime = (58.8) / (60 * 60 * 24) #days, see Kepler Data Processing Handbook, Section 3.1\n",
    "\n",
    "def get_kepler_data(kic_id, exptime='long'):\n",
    "\n",
    "    start = time.time()\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `kic_id`: Kepler ID (str)\n",
    "    `exptime`: default exposure time, 'long'\n",
    "\n",
    "    ## Outputs:\n",
    "    Returns a 4-tuple:\n",
    "    - `lc`:  Lightkurve lc object (or nan if failed)\n",
    "    - `delta_f`: frequency resolution, 1 / total observation time\n",
    "    - `sampling_time`: median time between observations (in days)\n",
    "    - `exptime`:  exposure time in days (from global `lc_exptime` or `sc_exptime`)\n",
    "\n",
    "    ## Bugs:\n",
    "    - Depends on global vals: `lc_exptime`, `sc_exptime` \n",
    "    - Fails silently when no data found\n",
    "    - Rejects light curves where any `dt < 0.9 * median(dt)` — may be too strict\n",
    "    - Uses magic thresholds for time sampling\n",
    "    \"\"\"\n",
    "    search_result = lk.search_lightcurve(kic_id, mission = 'Kepler', exptime=exptime)\n",
    "    \n",
    "    if len(search_result) < 1:\n",
    "        print(f\"get_kepler_data(): no results for {kic_id} at this cadence\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    try:\n",
    "        lc_collection = search_result.download_all()\n",
    "    \n",
    "    except LightkurveError:\n",
    "        print(f\"LightkurveError for {kic_id}: get_kepler_data(): search_result.download_all() failed for {kic_id}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    lc = lc_collection.stitch()\n",
    "    if check_inputs(lc.time.value) is False:\n",
    "        time_val, __ = reorder_inputs(lc.time.value, lc.flux.value)\n",
    "    else:\n",
    "        time_val, __ = lc.time.value, lc.flux.value\n",
    "\n",
    "    if not np.all(np.diff(time_val) > 0):\n",
    "        print(\"nana.star(): times not in order\")\n",
    "        #raise ValueError(\"Times are not in order\")\n",
    "    delta_f = (1/(time_val[-1] - time_val[0]))\n",
    "    sampling_time= np.median(np.diff(time_val))\n",
    "\n",
    "    if not np.all(np.diff(time_val) > 0.90 * sampling_time): #magic\n",
    "        print(\"nana.star(): some time intervals out of spec\")\n",
    "        print(\"nana.star(): median dt = \", sampling_time)\n",
    "        #raise ValueError(\"some time intervals out of spec\")\n",
    "    \n",
    "    exptime = np.nan\n",
    "    if sampling_time > 0.9 * lc_exptime:  #magic number?\n",
    "        exptime = lc_exptime\n",
    "        print(f\"{kic_id} is long cadence\")\n",
    "    if sampling_time < 1.1 * sc_exptime: #also magic number?\n",
    "        exptime = sc_exptime\n",
    "        print(f\"{kic_id} is short cadence\")\n",
    "    if exptime is np.nan:\n",
    "        print(\"nana.star(): no consistent exptime\")\n",
    "        #raise ValueError(\"no consistent exptime\")\n",
    "    print(\"nana.get_kepler_data() took\", time.time() - start, \"seconds\")\n",
    "    return lc, delta_f, sampling_time, exptime\n",
    "\n",
    "def mask_vals(lc):\n",
    "    \"\"\"\n",
    "    Remove mask values from a Lightkurve LightCurve object and return valid time, flux, and weight arrays.\n",
    "\n",
    "    ## Inputs:\n",
    "    `lc`: Lightkurve LightCurve object:\n",
    "    - `\n",
    "\n",
    "    ## Outputs:\n",
    "    3 NumPy arrays:\n",
    "    - `t_fit`: time values with valid (finite) data\n",
    "    - `flux_fit`: corresponding flux values\n",
    "    - `weight_fit`: corresponding weights (1 / sigma^2)\n",
    "\n",
    "    ## Bugs:\n",
    "    - not obvious that we need this function\n",
    "    \"\"\"\n",
    "    #replaces masked values with NaN\n",
    "    #print(type(lc.flux)) --> confirmed that lc.flux is a MaskedArray\n",
    "    t_clean = np.ma.filled(lc.time.value, np.nan)\n",
    "    flux_clean = np.ma.filled(lc.flux.value, np.nan)\n",
    "    sigma_clean = np.ma.filled(lc.flux_err.value, np.nan)\n",
    "\n",
    "    #gets rid of NaNs, creates mask with only finite/valid values\n",
    "    mask = np.isfinite(t_clean) & np.isfinite(flux_clean) & np.isfinite(sigma_clean)\n",
    "    t_fit = t_clean[mask]\n",
    "    flux_fit = flux_clean[mask]\n",
    "    sigma_fit = sigma_clean[mask]\n",
    "    weight_fit = 1 / sigma_fit**2\n",
    "\n",
    "    return t_fit, flux_fit, weight_fit\n",
    "\n",
    "def check_inputs(xs):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: list of lc time values (numpy array)\n",
    "\n",
    "    ## Outputs:\n",
    "    `bool`: `True` if the array is sorted, `False` otherwise\n",
    "    \"\"\"\n",
    "    for i in range(len(xs) - 1):\n",
    "        if xs[i] > xs[i + 1]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def reorder_inputs(xs, ys):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: lc time values (numpy array)  \n",
    "    `ys`: lc flux values (numpy array)\n",
    "\n",
    "    ## Outputs:\n",
    "    A tuple `(xs_sorted, ys_sorted)` where:\n",
    "    - `xs_sorted`: `xs` sorted in ascending order\n",
    "    - `ys_sorted`: corresponding `ys` values reordered to match `xs_sorted`\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `xs` and `ys` are NumPy arrays\n",
    "    - Raises a ValueError if `xs` and `ys` have different lengths\n",
    "    \"\"\"\n",
    "    if len(xs) != len(ys):\n",
    "        raise ValueError(\"reorder_inputs(): `xs` and `ys` must be the same length\")\n",
    "    i = np.argsort(xs)\n",
    "    return xs[i], ys[i]\n",
    "\n",
    "def get_periodogram(f_min, f_max, df, lc):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `f_min`: minimum frequency (float, 1/day) — sets frequency resolution  \n",
    "    `f_max`: maximum frequency (float, 1/day)  \n",
    "    `lc`: Lightkurve LightCurve object\n",
    "\n",
    "    ## Outputs:\n",
    "    Two NumPy arrays:\n",
    "    - `freq_full`: frequency grid (1/day)  \n",
    "    - `power_full`: corresponding Lomb-Scargle power spectrum values\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `f_min` > 0 and `f_max` > `f_min`\n",
    "    \"\"\"\n",
    "    \n",
    "    frequency_grid = np.arange(f_min, f_max, df) / u.day\n",
    "    pg = lc.to_periodogram(\n",
    "        method='lombscargle',\n",
    "        normalization='psd',\n",
    "        frequency=frequency_grid\n",
    "    )\n",
    "    power = pg.power.value\n",
    "    freq = pg.frequency.to(1 / u.day).value\n",
    "    return freq, power\n",
    "\n",
    "def design_matrix(xlist):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xlist`: numpy array of length 3 for the three frequency points (middle and two neighbors)\n",
    "\n",
    "    ## Outputs:\n",
    "    A 3x3 design matrix:\n",
    "    - Column 1: constant term (1s)\n",
    "    - Column 2: linear term (`xlist`)\n",
    "    - Column 3: quadratic term with 0.5 factor (`0.5 * xlist**2`)\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `xlist` has length 3 \n",
    "    - Assumes `xlist` is ordered\n",
    "\n",
    "    ## Notes:\n",
    "    - Includes a 0.5 factor that Hogg likes in the quadratic term \n",
    "    \"\"\"\n",
    "    return (np.vstack((xlist**0, xlist**1, 0.5 * xlist**2))).T\n",
    "\n",
    "def fit_parabola(xs, ys, index):\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: numpy array of frequency values\n",
    "    `ys`: numpy array of power values \n",
    "    `index`: integer index of the central point to fit around\n",
    "\n",
    "    ## Outputs:\n",
    "    Tuple `(b, m, q)` representing coefficients of the quadratic:  \n",
    "\n",
    "    ## Bugs:\n",
    "    - `xs` and `ys` must be numpy arrays\n",
    "    - Index must not be 0 or `len(xs) - 1`; otherwise will be out of bounds\n",
    "    \"\"\"\n",
    "    #index = int(index)\n",
    "    if index < 1 or index > len(xs) - 2:\n",
    "        raise IndexError(\"fit_parabola(): index must be between 1 and len(xs) - 2\")\n",
    "    return np.linalg.solve(design_matrix(xs[index-1:index+2]), ys[index-1:index+2])\n",
    "\n",
    "def refine_peak(xs, ys, index):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: numpy array of frequency values \n",
    "    `ys`: numpy array of power values\n",
    "    `index`: integer index of peak to refine\n",
    "\n",
    "    ## Outputs:\n",
    "    3-tuple `(x_peak, y_peak, q)` where:\n",
    "    - `x_peak`: refined x-position of the peak \n",
    "    - `y_peak`: refined y-position\n",
    "    - `q`: second derivative\n",
    "\n",
    "    ## Bugs:\n",
    "    - Must be synchronized with the design matrix (uses same quadratic form)\n",
    "    \"\"\"\n",
    "    b, m, q = fit_parabola(xs, ys, index)\n",
    "    x_peak = -m / q\n",
    "    if x_peak < xs[0] or x_peak > xs[-1]:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    y_peak = 0.5 * q * x_peak**2 + m * x_peak + b\n",
    "    return x_peak, y_peak, q\n",
    "\n",
    "def refine_peaks(xs, ys, indices):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: numpy array of frequency values\n",
    "    `ys`: numpy array of power values\n",
    "    `indices`: numpy array of frequency peak indices\n",
    "\n",
    "    ## Outputs:\n",
    "    Three NumPy arrays:\n",
    "    - `xs_refined`: refined x positions of peaks\n",
    "    - `ys_refined`: refined y positions of peaks\n",
    "    - `second_derivatives`: curvature values (second derivative q for each peak)\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all `indices` are valid (i.e., between 1 and len(xs) - 2) \n",
    "    - Assumes `xs` and `ys` are numpy arrays and ordered\n",
    "    \"\"\"\n",
    "    n = len(indices)\n",
    "    xs_refined = np.full(n, np.nan)\n",
    "    ys_refined = np.full(n, np.nan)\n",
    "    second_derivatives = np.full(n, np.nan)\n",
    "    \n",
    "    for j, i in enumerate(indices):\n",
    "        if np.isnan(i):\n",
    "            continue\n",
    "        else:\n",
    "            result = refine_peak(xs, ys, i)\n",
    "            x_r, y_r, q_r = result\n",
    "            xs_refined[j] = x_r\n",
    "            ys_refined[j] = y_r\n",
    "            second_derivatives[j] = q_r\n",
    "            \n",
    "    return np.array(xs_refined), np.array(ys_refined), np.array(second_derivatives)\n",
    "\n",
    "def get_filtered_peaks(num_of_peaks, xs, ys, median_window = None, median_factor = 20.): #median_factor is magic\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `num_of_peaks`: number of peaks to return  \n",
    "    `xs`: numpy array of x values (frequencies)  \n",
    "    `ys`: numpy array of y values (power spectrum)\n",
    "\n",
    "    ## Outputs:\n",
    "    NumPy array of peak indices (length ≤ `num_of_peaks`), filtered to avoid clustering and remove small peaks\n",
    "\n",
    "    ## Bugs:\n",
    "    - Depends on global variable `f_avoid`, which must be defined externally\n",
    "    - Assumes `xs` is ordered and evenly spaced\n",
    "    - No NaN handling in `ys`\n",
    "    - uses append in a double loop\n",
    "    \"\"\" \n",
    "    indxs, _ = find_peaks(ys)\n",
    "    filtered = []\n",
    "\n",
    "    if len(indxs) == 0:\n",
    "        print(\"get_filtered_peaks(): no peaks found\")\n",
    "        return np.array(filtered)\n",
    "    \n",
    "    indices = indxs[np.argsort(-ys[indxs])]\n",
    "\n",
    "    if median_window is not None:\n",
    "        y_medians = median_filter(ys, size=median_window) #median window def magic\n",
    "        too_short = ys[indices] < median_factor * y_medians[indices]\n",
    "        indices = np.delete(indices, too_short)\n",
    "    \n",
    "    if len(indices) == 0:\n",
    "        print(\"get_filtered_peaks(): no peaks tall enough\")\n",
    "        return np.array(filtered)\n",
    "\n",
    "    #checks if the peak is within some threshold by comparing to those that already passed frequencies\n",
    "    for index in indices:\n",
    "        if all(abs(xs[index] - xs[fil]) >= f_avoid for fil in filtered):\n",
    "            filtered.append(index)\n",
    "            if len(filtered) == num_of_peaks:\n",
    "                break\n",
    "    return np.array(filtered)\n",
    "\n",
    "def folding_freq(delta_f, fs, ps, sampling_time, makeplots=False):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `delta_f`: frequency resolution\n",
    "    `fs`: numpy array of frequency values \n",
    "    `ps`: numpy array of power values corresponding to `fs`  \n",
    "    `sampling_time`: sampling interval in days  \n",
    "    `makeplots`: bool, whether to plot\n",
    "\n",
    "    ## Outputs:\n",
    "    `fc`: refined estimate of the folding frequency\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `fs` is strictly ordered (required for spline and peak detection)\n",
    "    - Removes first and last two points (`fsA = fsA[2:-2]`), assumes enough data\n",
    "    \"\"\"\n",
    "    fc_guess = 1. / sampling_time\n",
    "    IA = fs < 0.5 * fc_guess\n",
    "    fsA, psA = fs[IA], ps[IA]\n",
    "    fsA, psA = fsA[2:-2], psA[2:-2] #magic???\n",
    "\n",
    "    cs = CubicSpline(fs, ps, extrapolate=False)\n",
    "\n",
    "    small, tiny = 20 * delta_f, 0.25 * delta_f #magic\n",
    "    fc_candidates = np.arange(fc_guess - small, fc_guess + small, tiny)\n",
    "    #this should just be one line of numpy\n",
    "    #check how much original powers from Region A match with the interpolated powers in Region A from fc_candidates\n",
    "    foos_c = np.array([np.nansum(psA * cs(fc - fsA)) for fc in fc_candidates])\n",
    "    fc_index = np.argmax(foos_c)\n",
    "    fc, _, _ = refine_peak(fc_candidates, foos_c, fc_index)\n",
    "\n",
    "    if makeplots:\n",
    "        plt.plot(fc_candidates, foos_c)\n",
    "        plt.axvline(fc_guess)\n",
    "        plt.axvline(fc, color='red', alpha=0.5)\n",
    "        plt.title(f\"Refined folding frequency: {fc:0.5f}\")\n",
    "        plt.show()\n",
    "\n",
    "    return fc\n",
    "\n",
    "def find_min_and_refine(xs, ys):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `xs`: numpy array of x values  \n",
    "    `ys`: numpy array of y values \n",
    "\n",
    "    ## Outputs:\n",
    "    Tuple `(refined_x, refined_y)` where:\n",
    "    - `refined_x`: x-position of the refined minimum\n",
    "    - `refined_y`: y-value at the refined minimum\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `xs` and `ys` are NumPy arrays of equal length\n",
    "    - Assumes `xs` is ordered\n",
    "    - Raises `ValueError` if no local minima are found\n",
    "    - Raises `IndexError` if minimum is at the edge (index 0 or len-1)\n",
    "    \"\"\"\n",
    "    #ys = np.asarray(list(ys))\n",
    "    \n",
    "    indxs, _ = find_peaks(-ys)\n",
    "\n",
    "    if len(indxs) == 0:\n",
    "        return np.nan, np.nan\n",
    "        #raise ValueError(\"find_min_and_refine(): no local minima found\")\n",
    "    \n",
    "    min_index = indxs[np.argsort(ys[indxs])[:1]]\n",
    "    if min_index < 1 or min_index > len(xs) - 2:\n",
    "        raise IndexError(\"find_min_and_refine(): minimum too close to edge to refine\")\n",
    "    \n",
    "    refined_x, refined_y, _ = refine_peaks(xs, ys, min_index)\n",
    "    return refined_x[0], refined_y[0]\n",
    "\n",
    "def integral_design_matrix(ts, om, T):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `ts`: list of N times (days)\n",
    "    `om`: angular frequency (inverse days)\n",
    "    `T`: exposure time (days)\n",
    "\n",
    "    ## Outputs:\n",
    "    `X`: Nx3 design matrix\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all data points have the same exposure time `T`\n",
    "    - Not numerically stable when `om * T` is small\n",
    "    \"\"\"\n",
    "    return np.vstack([\n",
    "        np.ones_like(ts),\n",
    "        (np.sin(om * (ts + T / 2)) - np.sin(om * (ts - T / 2))) / (om * T),\n",
    "        (-np.cos(om * (ts + T / 2)) + np.cos(om * (ts - T / 2))) / (om * T)\n",
    "    ]).T\n",
    "\n",
    "def weighted_least_squares(A, b, weights):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `A`: NxM design matrix (NumPy array)  \n",
    "    `b`: N-length observation vector (NumPy array)  \n",
    "    `weights`: N-length vector of weights (NumPy array), applied per row\n",
    "\n",
    "    ## Outputs:\n",
    "    N-length fitted model values `A @ x`, where `x` solves the weighted least squares problem\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all inputs are NumPy arrays of compatible shape\n",
    "    \"\"\"\n",
    "\n",
    "    ATA = A.T @ (A * weights[:, np.newaxis])\n",
    "    ATb = A.T @ (b * weights)\n",
    "    return np.linalg.solve(ATA, ATb)\n",
    "\n",
    "def integral_chi_squared(om, ts, ys, ws, T):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `om`: angular frequency (in inverse days)  \n",
    "    `ts`: numpy array of observation times (in days)  \n",
    "    `ys`: numpy array of observed flux values  \n",
    "    `ws`: numpy array of weights (same length as `ts` and `ys`)  \n",
    "    `T`: exposure time (in days)\n",
    "\n",
    "    ## Outputs:\n",
    "    Weighted chi-squared value computed using the integral design matrix model\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes all inputs are NumPy arrays of compatible shapes\n",
    "    - Assumes uniform exposure time `T` for all observations\n",
    "    - Numerically unstable when `om * T` is small (from `integral_design_matrix`)\n",
    "    \"\"\"\n",
    "    A = integral_design_matrix(ts, om, T)\n",
    "    return np.sum(ws * (ys - (A @ weighted_least_squares(A, ys, ws)))**2)\n",
    "\n",
    "\n",
    "def region_and_freq(indices, folding_freq, f_min, unrefined_freq, unrefined_power, t_fit, flux_fit, weight_fit, T):\n",
    "    start = time.time()\n",
    "\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `indices`: array of peak indices\n",
    "    `folding_freq`: folding frequency   \n",
    "    `df`: frequency resolution\n",
    "    `unrefined_freq`: array of frequency values  \n",
    "    `unrefined_power`: power spectrum values corresponding to `unrefined_freq`  \n",
    "    `t_fit`: time values used for model fitting  \n",
    "    `flux_fit`: observed signal (e.g., flux)  \n",
    "    `weight_fit`: weights for fitting  \n",
    "    `T`: exposure time in days\n",
    "\n",
    "    ## Outputs:\n",
    "    Three NumPy arrays:\n",
    "    - `regions`: array of region labels (`\"A\"`, `\"B\"`, `\"C\"`)\n",
    "    - `best_freqs`: refined frequency values for each peak\n",
    "    - `best_chi2s`: corresponding chi-squared values\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `refine_peaks` succeeds for all given indices\n",
    "    - No handling if `fine_freqsX` are empty or out of bounds\n",
    "    - probably this should just run on one index at a time, and the loop over indices should ne in the calling function\n",
    "    \"\"\"\n",
    "    valid_locs = [j for j, val in enumerate(indices) if not np.isnan(val)]\n",
    "    valid_indices = [indices[j] for j in valid_locs]\n",
    "    \n",
    "    N = len(indices)\n",
    "    regions = np.full(N, np.nan, dtype=object)\n",
    "    best_freqs = np.full(N, np.nan)\n",
    "    best_chi2s = np.full(N, np.nan)\n",
    "\n",
    "    fas, _, _ = refine_peaks(unrefined_freq, unrefined_power, valid_indices)\n",
    "    \n",
    "    A, B, C = fas, folding_freq - fas, folding_freq + fas\n",
    "\n",
    "    for i, loc in enumerate(valid_locs):\n",
    "        fine_freqsA = np.arange(A[i] - 5 * f_min, A[i] + 5 * f_min, 0.2 * f_min) #magic, and so are all fine_freqs\n",
    "        #chi2_fineA = np.array([integral_chi_squared(2 * np.pi * f, t_fit, flux_fit, weight_fit, T) for f in fine_freqsA])\n",
    "        #print(\"chi2_fineA\", chi2_fineA)\n",
    "        chi2_fineA = np.array([integral_chi_squared(2 * np.pi * f, t_fit, flux_fit, weight_fit, T) for f in fine_freqsA])\n",
    "\n",
    "        #print(\"chi2_fineA\", chi2_fineA)\n",
    "        best_freqA, best_chi2A = find_min_and_refine(fine_freqsA, chi2_fineA)\n",
    "\n",
    "        fine_freqsB = np.arange(B[i] - 5 * f_min, B[i] + 5 * f_min, 0.2 * f_min)\n",
    "        chi2_fineB = np.array([integral_chi_squared(2 * np.pi * f, t_fit, flux_fit, weight_fit, T) for f in fine_freqsB])\n",
    "        best_freqB, best_chi2B = find_min_and_refine(fine_freqsB, chi2_fineB)\n",
    "\n",
    "        fine_freqsC = np.arange(C[i] - 5 * f_min, C[i] + 5 * f_min, 0.2 * f_min)\n",
    "        chi2_fineC = np.array([integral_chi_squared(2 * np.pi * f, t_fit, flux_fit, weight_fit, T) for f in fine_freqsC])\n",
    "        best_freqC, best_chi2C = find_min_and_refine(fine_freqsC, chi2_fineC)\n",
    "\n",
    "        freqs = np.array([best_freqA, best_freqB, best_freqC])\n",
    "        chi2s = np.array([best_chi2A, best_chi2B, best_chi2C])\n",
    "        regs = np.array(['A', 'B', 'C'])\n",
    "\n",
    "        no_nans = ~np.isnan(chi2s)\n",
    "\n",
    "        if np.any(no_nans):\n",
    "            freqs = freqs[no_nans]\n",
    "            chi2s = chi2s[no_nans]\n",
    "            regs = regs[no_nans]\n",
    "\n",
    "            low_chi_ind = np.argmin(chi2s)\n",
    "            regions[loc] = regs[low_chi_ind]\n",
    "            best_freqs[loc] = freqs[low_chi_ind]\n",
    "            best_chi2s[loc] = chi2s[low_chi_ind]\n",
    "    print(\"region_and_freq() took\", time.time() - start, \"seconds\")\n",
    "\n",
    "    delta_chi2s =  null_chi_squared(flux_fit, weight_fit) - best_chi2s\n",
    "\n",
    "    output_table = Table()\n",
    "    output_table['frequency'] = best_freqs\n",
    "    output_table['region'] = regions\n",
    "    output_table['delta chi-squared'] = delta_chi2s\n",
    "    output_table['frequency in region A'] = fas\n",
    "\n",
    "    return output_table\n",
    "    #return regions, best_freqs, best_chi2s\n",
    "\n",
    "def sharpness(second_derivatives, y_news):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `second_derivatives`: NumPy array of second derivatives\n",
    "    `y_news`: NumPy array of peak heights or values at the vertex of the parabola\n",
    "\n",
    "    ## Outputs:\n",
    "    NumPy array of sharpness values, defined as sqrt(-q / y)\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `y_news` and `second_derivatives` are same-length NumPy arrays\n",
    "    - Assumes `y_news` ≠ 0 and `second_derivatives` < 0 (for real output)\n",
    "    \"\"\"\n",
    "\n",
    "    second_derivatives = np.asarray(second_derivatives)\n",
    "    y_news = np.asarray(y_news)\n",
    "    N = len(second_derivatives)\n",
    "\n",
    "    sharps = np.full(N, np.nan)\n",
    "    for i in range(N):\n",
    "        if np.isnan(second_derivatives[i]) or np.isnan(y_news[i]):            \n",
    "            sharps[i] = (-second_derivatives[i] / y_news[i]) ** 0.5\n",
    "\n",
    "    return sharps\n",
    "\n",
    "\n",
    "def null_chi_squared(ys, weights):\n",
    "    \"\"\"\n",
    "    ## Inputs:\n",
    "    `ys`: numpy array of observed values (e.g., flux)  \n",
    "    `weights`: numpy array of weights corresponding to `ys`\n",
    "\n",
    "    ## Outputs:\n",
    "    `null_chisq`: weighted chi-squared value\n",
    "\n",
    "    ## Bugs:\n",
    "    - Assumes `ys` and `weights` are NumPy arrays of the same length\n",
    "    - Raises `ZeroDivisionError` if the sum of weights is zero \n",
    "    \"\"\"\n",
    "    total_weight = np.sum(weights)\n",
    "    if total_weight == 0:\n",
    "        raise ZeroDivisionError(\"null_chi_squared(): sum of weights is zero\")\n",
    "    \n",
    "    a0 = np.sum(weights * ys) / total_weight\n",
    "    null_chisq = np.sum(weights * (ys - a0) ** 2)\n",
    "    return np.array(null_chisq)\n",
    "\n",
    "def splitting(ts, K, jackknife = True):\n",
    "    '''\n",
    "    # splitting()\n",
    "    Produce either disjoint or jackknife subsamples.\n",
    "    \n",
    "    ## Inputs:\n",
    "    - `ts`: shape `(N, )` array of times (not necesarily ordered)\n",
    "    - `K`: number of subsamples to return\n",
    "    - `jackknife`: `True` for jackknife subsamples; otherwise disjoint\n",
    "    \n",
    "    ## Output: \n",
    "    - `masks`: shape `(K, N)` boolean array; `True` if in subsample\n",
    "\n",
    "    ## Comment:\n",
    "    - Relies on numpy conventions about relationships between integers and bools.\n",
    "    '''\n",
    "    N = len(ts)\n",
    "    indices = np.argsort(ts)\n",
    "    split_indices = np.array_split(indices, K)\n",
    "    if jackknife:\n",
    "        masks = np.ones((K, N), dtype=bool) # make everything True by default\n",
    "        for i, idx in enumerate(split_indices):\n",
    "            masks[i, idx] = False # remove subsample\n",
    "    else:\n",
    "        masks = np.zeros((K, N), dtype=bool) # make everything False by default\n",
    "        for i, idx in enumerate(split_indices):\n",
    "            masks[i, idx] = True # add subsample\n",
    "    return masks\n",
    "\n",
    "def check_coherence(ts, ys, weights, T, output_table):\n",
    "    '''\n",
    "    ## Inputs:\n",
    "    - `ts`: time values \n",
    "    - `ys`: flux values \n",
    "    - `weights`: weights for the observations \n",
    "    - `final_freq`: final frequencies to check coherence for \n",
    "    - `T`: exposure time \n",
    "\n",
    "    ## Outputs:\n",
    "   - `all`: shape `(N, 2)` array of a,b pars fit over full data\n",
    "    - `half`: shape `(N, 2, 2)` a,b pars fits over halves\n",
    "    - `quarter`: shape `(N, 4, 2)` a,b pars fits over quarters\n",
    "    - `eighth`: shape `(N, 8, 2)` a,b pars fits over eighths +(jackknife)\n",
    "    '''\n",
    "    final_freq = output_table[\"frequency\"]\n",
    "    N = len(final_freq)\n",
    "    all = np.full((N, 2), np.nan)\n",
    "        \n",
    "\n",
    "    splits = np.array([2, 4, 8])\n",
    "    results = [np.full((N, n, 2), np.nan) for n in splits]\n",
    "    \n",
    "    for idx, f in enumerate(final_freq):\n",
    "        if np.isnan(f):\n",
    "            continue\n",
    "        om = f * 2 * np.pi \n",
    "        A = integral_design_matrix(ts, om, T)\n",
    "        pars = weighted_least_squares(A, ys, weights)\n",
    "        all[idx][0] = pars[1]\n",
    "        all[idx][1] = pars[2]\n",
    "\n",
    "    for split, result in zip(splits, results):     \n",
    "\n",
    "        jack = (split == 8)\n",
    "        masks = splitting(ts, split, jackknife = jack)\n",
    "        for idx, f in enumerate(final_freq):\n",
    "            if np.isnan(f):\n",
    "                continue\n",
    "            om = f * 2 * np.pi\n",
    "            for i, mask in enumerate(masks):\n",
    "                A = integral_design_matrix(ts[mask], om, T)\n",
    "                pars = weighted_least_squares(A, ys[mask], weights[mask])\n",
    "                result[idx][i][0] = pars[1] #a\n",
    "                result[idx][i][1] = pars[2] #b\n",
    "\n",
    "    return all, results[0], results[1], results[2] #all, half, quarter, eighth (+jacknives)\n",
    "\n",
    "\n",
    "def sampling_stats(alls, halves, quartiles, eighths, ts, output_table):\n",
    "    '''\n",
    "    sampling_stats():\n",
    "    Calculate  statistics on oscillation amplitude and phase\n",
    "    ## Inputs:\n",
    "    - `all`: shape `(N, 2)` array of a,b pars fit over full data\n",
    "    - `half`: shape `(N, 2, 2)` a,b pars fits over halves\n",
    "    - `quarter`: shape `(N, 4, 2)` a,b pars fits over quarters\n",
    "    - `eighth`: shape `(N, 8, 2)` a,b pars fits over eighths +(jackknife)\n",
    "    - `ts`: time values\n",
    "\n",
    "    ## Outputs:\n",
    "    - `amp_change2`:  array of log-amplitude change rates from halves\n",
    "    - `phase_change2`: array of phase change rates from halves\n",
    "    - `amp_change4`: (N, 4)` relative log amplitude changes from quartiles\n",
    "    - `phase_change4`: (N, 4)` relative phase shifts from quartiles\n",
    "    - `sigma_lnA4`:  array of ln-amplitude across quartiles (1/2 RMS)\n",
    "    - `sigma_phi4`:  array of phase across quartiles (1/2 RMS)\n",
    "    - `sigma_phij`:  array of phase from jackknife eighths (sigma estimate)\n",
    "\n",
    "    ## Comment:\n",
    "    - halves statsitics are calculated from comparison between the first and second halves parameters\n",
    "    - quartiles and eighth jacknife stats\n",
    "      are calculated from relative shift from the all parameters to the quartile and eighth parameters\n",
    "    '''\n",
    "\n",
    "    f_num = len(alls)\n",
    "    ts_median = np.median(ts)\n",
    "    delta_t = np.median(ts[ts > ts_median]) - np.median(ts[ts < ts_median])\n",
    "    amp_change2 = np.full((f_num), np.nan)\n",
    "    phase_change2 = np.full((f_num), np.nan)\n",
    "    \n",
    "    amp_change4 = np.full((f_num, 4), np.nan) #change in rate of ln(amp) for quartile\n",
    "    phase_change4 = np.full((f_num, 4), np.nan) #change in rate of phase for quartile\n",
    "\n",
    "    sigma_lnA4 = np.full(f_num, np.nan) # 1/2 rms lnA for quartile\n",
    "    sigma_phi4 = np.full(f_num, np.nan) # 1/2 rms phase for quartile\n",
    "    sigma_phij = np.full(f_num, np.nan) #sigma phi for jacknife\n",
    "    \n",
    "    for inx, (all, half, quartile, eighth) in enumerate(zip(alls, halves, quartiles, eighths)):\n",
    "\n",
    "        #change in rate of ln(a) and phase calcualtion for halves\n",
    "        \n",
    "        a1, b1, a2, b2 = half[0][0], half[0][1], half[1][0], half[1][1]\n",
    "        if any(np.isnan([a1, a2, b1, b2])):\n",
    "            continue\n",
    "        delta_r = [a2 - a1, b2 - b1]\n",
    "        vector_r = [0.5 * (a2 + a1), 0.5 * (b2 + b1)]\n",
    "        cross_z = delta_r[0] * vector_r[1] - delta_r[1] * vector_r[0]\n",
    "        dot_r = np.dot(vector_r, vector_r)\n",
    "\n",
    "        phase_change2[inx] = (1 / delta_t) * (cross_z / dot_r)\n",
    "        amp_change2[inx]   = (1 / delta_t) * (np.dot(delta_r, vector_r) / dot_r)\n",
    "\n",
    "\n",
    "        #quartile and jacknife calcualtions\n",
    "        deltak_4 = np.zeros((4,2))\n",
    "        deltak_j = np.zeros((8,2))\n",
    "        a,b = all[0], all[1]\n",
    "        if np.isnan(a) or np.isnan(b):\n",
    "            continue\n",
    "        \n",
    "        for i, q in enumerate(quartile):   \n",
    "            deltak_4[i] = [a - q[0], b - q[1]]\n",
    "\n",
    "        for i, j in enumerate(eighth):   \n",
    "            deltak_j[i] = [a - j[0], b - j[1]]\n",
    "                \n",
    "        x = np.array([a,b])\n",
    "        x_norm = np.linalg.norm([a, b])\n",
    "        x_hat = x / x_norm\n",
    "        y_hat = [x_hat[1], - x_hat[0]]\n",
    "\n",
    "        amp4 = np.dot(deltak_4, x_hat)/ x_norm\n",
    "        phase4 = np.dot(deltak_4, y_hat)/x_norm\n",
    "        phasej = np.dot(deltak_j, y_hat)/x_norm\n",
    "\n",
    "        var_lnA = 0.5 * np.sqrt(np.mean(amp4 ** 2))#1/2 rms lnA\n",
    "        varphi4 = 0.5 * np.sqrt(np.mean(phase4 ** 2)) #1/2 rms phase\n",
    "\n",
    "        varphij = np.sqrt((7/8) * np.sum(phasej ** 2)) #sigma phi\n",
    "\n",
    "        amp_change4[inx] = amp4\n",
    "        phase_change4[inx] = phase4\n",
    "\n",
    "        sigma_lnA4[inx] = var_lnA\n",
    "        sigma_phi4[inx] = varphi4\n",
    "        sigma_phij[inx] = varphij\n",
    "    \n",
    "    #make astropy table\n",
    "    #print(sigma_phij.shape)\n",
    "    output_table.add_columns([sigma_phij,  sigma_phi4, phase_change2, phase_change4], names = ['phase uncertainty jackknife', 'phase uncertainty split', 'phase change for A-B split', 'phase change for quartile split'])\n",
    "    #print(\"output table adding columns\", output_table)\n",
    "    return output_table\n",
    "\n",
    "def inject_one_mode(ts, ys, T, in_pars):\n",
    "    '''\n",
    "    # inject_one_mode()\n",
    "    adds a mode\n",
    "\n",
    "    ## Inputs:\n",
    "    - `ts`: array of time values\n",
    "    - `ys`: array of flux values (original signal)\n",
    "    - `T`:  exposure time \n",
    "    - `in_pars`: tuple `(f, a, b)`:\n",
    "        - `f`: frequency to inject \n",
    "        - `a`, `b`: cosine and sine pars\n",
    "\n",
    "    ## Output:\n",
    "    - `yin`: `(N,)` array of modified flux values with injected mode\n",
    "    '''\n",
    "    #yin is the new fluxfit\n",
    "    fin, ain, bin = in_pars\n",
    "    inject_vec = np.array([0.0, ain, bin])   \n",
    "\n",
    "    xin = integral_design_matrix(ts, 2 * np.pi * fin, T)\n",
    "    yin = ys + xin @ inject_vec  \n",
    "    \n",
    "    return yin \n",
    "\n",
    "def RunningMedian(x, N):\n",
    "    return median_filter(x, N)\n",
    "\n",
    "    #return np.array([np.median(c) for c in b])  # This also works\n",
    "\n",
    "def find_modes_in_star(kicID, plots = False, save = False, inject_rng = None, inject_amp = 0.01, \n",
    "                       max_peaks = 24, chi2_threshold = 100, phase_uncertainty_threshold = 0.1, \n",
    "                       median_window = 21, median_factor = 20.): #basically all magic here\n",
    "    \n",
    "    start = time.time()\n",
    "    #output_dir = os.path.join(\"testing\", f\"{kicID}\")\n",
    "    #os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"working on {kicID}\")\n",
    "\n",
    "    \n",
    "    #get the lightcurve\n",
    "    kicID = \"KIC\" + str(kicID).lstrip(\"0\") \n",
    "    lc, delta_f, sampling_time, exptime = get_kepler_data(kicID)\n",
    "\n",
    "    if np.isnan(delta_f):\n",
    "        print(f\"Skipping {kicID} because get_kepler_data() returned nans\")\n",
    "        return None\n",
    "    \n",
    "    t_fit, flux_fit, weight_fit = mask_vals(lc) \n",
    "\n",
    "    #set frequency variables  \n",
    "    over_sampling  = 3 #oversample by a factor of 3\n",
    "    df, f_maxC = delta_f/over_sampling, (3 / (2*sampling_time))\n",
    "    f_min = over_sampling * df\n",
    "    \n",
    "    #if injecting, inject now\n",
    "    inject = False\n",
    "    if inject_rng is not None:\n",
    "        inject = True\n",
    "        ain,bin = inject_amp * inject_rng.normal(size = 2)\n",
    "        fin = inject_rng.uniform(f_min, f_maxC)\n",
    "        inject_pars = (fin, ain, bin)\n",
    "        print(\"injection\", inject_pars)\n",
    "        flux_fit = inject_one_mode(t_fit, flux_fit, exptime, inject_pars)\n",
    "        lc = LightCurve(time=t_fit, flux=flux_fit) #setting new lc to match yin\n",
    "    \n",
    "    #get periodograms in regions A, B, and C\n",
    "    freq_full, power_full = get_periodogram(f_min, f_maxC, df, lc)\n",
    "    fc = folding_freq(delta_f, freq_full, power_full, sampling_time, False)\n",
    "    fb = 0.5 * fc\n",
    "    freq_mini, power_mini = get_periodogram(f_min, fb, df, lc)\n",
    "\n",
    "    RunningMedian_power = RunningMedian(power_mini, 31) #31 is magic\n",
    "\n",
    "        \n",
    "\n",
    "    #find periodogram peaks in region A\n",
    "    indices = get_filtered_peaks(max_peaks, freq_mini, power_mini/RunningMedian_power, \n",
    "                                 median_window = median_window, median_factor = median_factor)\n",
    "    if len(indices) == 0:\n",
    "        print(f\"No peaks found in {kicID}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    #find frequencies and corresponding regions\n",
    "    #regions, final_freqs, chi2s = region_and_freq(indices, fc, df, freq_mini, power_mini, t_fit, flux_fit, weight_fit, exptime) #make the output table\n",
    "    output_table = region_and_freq(indices, fc, df, freq_mini, power_mini, t_fit, flux_fit, weight_fit, exptime)\n",
    "\n",
    "    #print(\"first output table\", output_table)\n",
    "    #print(f\"delta_chi2s for {kicID}:\", output_table[\"delta chi-squared\"])\n",
    "\n",
    "    good = ~np.isnan(output_table[\"frequency\"]) & (output_table[\"delta chi-squared\"] >= chi2_threshold) #filter out bad regions and low chi2\n",
    "    if np.sum(good) < 1:\n",
    "        print(f\"No frequencies found in {kicID} with chi2 threshold {chi2_threshold}\")\n",
    "        return None \n",
    "    output_table = output_table[good]\n",
    "    \n",
    "    #sharpnesses = sharpness(second_derivatives, refined_power)\n",
    "    all, half, quartiles, eighths = check_coherence(t_fit, flux_fit, weight_fit, exptime, output_table)\n",
    "\n",
    "    \n",
    "\n",
    "    output_table = sampling_stats(all, half, quartiles, eighths, t_fit, output_table)\n",
    "    \n",
    "    \n",
    "    good = (output_table['phase uncertainty jackknife'] <  phase_uncertainty_threshold)\n",
    "    if np.sum(good) < 1:\n",
    "        print(f\"No modes found in {kicID} with phase uncertainty threshold {phase_uncertainty_threshold}\")\n",
    "        return None\n",
    "    #bug: sampling_stats() should return a table object and this would only be one assignment\n",
    "    output_table = output_table[good]\n",
    "\n",
    "    #print(\"final output table\", output_table)\n",
    "\n",
    "    #full periodogram plotting (requires final_freqs)\n",
    "    if plots:\n",
    "        plt.plot(freq_full, power_full, 'k.', markersize = 1, alpha = 0.5)\n",
    "        for freq in output_table[\"frequency\"]:\n",
    "            plt.axvline(freq, color='red', alpha=0.50, lw = 0.5)\n",
    "        plt.xlabel(\"Frequency (1/day)\")\n",
    "        plt.ylabel(\"Power\")\n",
    "        plt.title(\"Frequencies that make chi2 cut\")\n",
    "        plt.axvline(fc)\n",
    "        plt.axvline(fc/2)\n",
    "        plt.semilogy()\n",
    "        if inject:\n",
    "            plt.title(f\"Full Injected Periodogram of {kicID}\")\n",
    "            if save:\n",
    "                plt.savefig(f\"{kicID}_injected_fullperio.png\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.title(f\"Full Periodogram of {kicID}\")\n",
    "            if save:\n",
    "                #plt.savefig(os.path.join(output_dir, f\"{kicID}_fullperio.png\"))\n",
    "                plt.savefig(f\"{kicID}_fullperio.png\")\n",
    "            #plt.show()   \n",
    "    \n",
    "    sigma_phi4 = output_table['phase uncertainty split']\n",
    "    sigma_phij = output_table['phase uncertainty jackknife']\n",
    "    final_freqs = output_table['frequency']\n",
    "    phase_change2 = output_table[ 'phase change for A-B split']\n",
    "    phase_change4 = output_table['phase change for quartile split']\n",
    "    regions = output_table['region']\n",
    "    delta_chi2s = output_table['delta chi-squared']\n",
    "    fas = output_table['frequency in region A']\n",
    "    \n",
    "    #sigmaphi plotting\n",
    "    if plots:\n",
    "        plt.scatter(sigma_phi4, sigma_phij, c = delta_chi2s, marker = 'o', s = 10, label = 'delta chi >= 100', cmap = \"viridis\")\n",
    "        plt.title(f\"sigma phi for {kicID}\")\n",
    "        plt.xlabel(\"sigma phis for quartiles\")\n",
    "        plt.ylabel(\"sigma phis for jackknives\")\n",
    "        plt.axvline(0.1, color = 'pink')\n",
    "        plt.axhline(0.1, color = 'pink')\n",
    "        plt.axvline(0.01, color = 'sandybrown')\n",
    "        plt.axhline(0.01, color = 'sandybrown')\n",
    "        plt.loglog()\n",
    "        plt.colorbar()\n",
    "        \n",
    "        if save:\n",
    "            plt.savefig(f\"{kicID}_phase_uncertainity_plot.png\")\n",
    "        #plt.show()\n",
    "\n",
    "    #15 point graph plotting\n",
    "    if plots:\n",
    "    \n",
    "        fig, axes = plt.subplots(3, 4, figsize=(16, 9))\n",
    "        plt.suptitle(f\"15 Point figure of {kicID}\", fontsize = 18)\n",
    "        \n",
    "        for idx, (ax, points1, points2, points3, points4, p1, p2, p3, p4) in enumerate(zip(axes.flat, all, half, quartiles, eighths, phase_change2, \n",
    "                                                                                           sigma_phi4, sigma_phij, phase_change4)):\n",
    "            if (np.isnan(points1).any() or np.isnan(points2).any() or np.isnan(points3).any() or np.isnan(points4).any()):                \n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                a_all = points1[0]\n",
    "                b_all = points1[1]\n",
    "        \n",
    "                a_half = [row[0] for row in points2 if not np.isnan(row[0]) and not np.isnan(row[1])]\n",
    "                b_half = [row[1] for row in points2 if not np.isnan(row[0]) and not np.isnan(row[1])]\n",
    "\n",
    "                a_quarter = [row[0] for row in points3 if not np.isnan(row[0]) and not np.isnan(row[1])]\n",
    "                b_quarter = [row[1] for row in points3 if not np.isnan(row[0]) and not np.isnan(row[1])]\n",
    "\n",
    "                a_eighth = [row[0] for row in points4 if not np.isnan(row[0]) and not np.isnan(row[1])]\n",
    "                b_eighth = [row[1] for row in points4 if not np.isnan(row[0]) and not np.isnan(row[1])]     \n",
    "        \n",
    "                ax.scatter(a_half, b_half, color='orange', marker='*')\n",
    "                ax.scatter(a_quarter, b_quarter, color='blue', marker='+')\n",
    "                ax.scatter(a_eighth, b_eighth, color='k', marker='.')\n",
    "                ax.scatter(a_all, b_all, color='red', marker='x')\n",
    "        \n",
    "                p1_str = f\"{p1:0.8e}\" if not np.isnan(p1) else \"None\"\n",
    "                p2_str = f\"{p2:0.8e}\" if not np.isnan(p2) else \"None\"\n",
    "                p3_str = f\"{p3:0.8e}\" if not np.isnan(p3) else \"None\"\n",
    "        \n",
    "                ax.text(0.05, 0.95, f\"phase change(2): {p1_str}\", transform=ax.transAxes,\n",
    "                        fontsize=8, verticalalignment='top', color='green')\n",
    "                ax.text(0.05, 0.88, f\"sigma phi(4): {p2_str}\", transform=ax.transAxes,\n",
    "                        fontsize=8, verticalalignment='top', color='green')\n",
    "                ax.text(0.05, 0.81, f\"sigma phi(jack): {p3_str}\", transform=ax.transAxes,\n",
    "                        fontsize=8, verticalalignment='top', color='green')\n",
    "        \n",
    "                freq_label = f\"{final_freqs[idx]:0.8f}\" if not np.isnan(final_freqs[idx]) else \"None\"\n",
    "                ax.set_title(freq_label)\n",
    "        \n",
    "                ax.axvline(0, color='k')\n",
    "                ax.axhline(0, color='k')\n",
    "                ax.set_xlabel(\"a points\")\n",
    "                ax.set_ylabel(\"b points\")\n",
    "                ax.grid(True)\n",
    "                ax.ticklabel_format(style='sci', scilimits=(-3, 3), axis='both')\n",
    "                ax.axis('equal')\n",
    "                \n",
    "        \n",
    "            except Exception as e:\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "\n",
    "        if inject:\n",
    "            if save:\n",
    "                plt.savefig(f\"{kicID}_injected_15point.png\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            if save:\n",
    "                #plt.savefig(os.path.join(output_dir, f\"{kicID}_15point.png\"))\n",
    "                plt.savefig(f\"{kicID}_15point.png\")\n",
    "            #plt.show()\n",
    "        plt.close(fig)\n",
    "        \n",
    "    print(\"find_modes_in_star() finished processing star\", kicID)\n",
    "    print(\"Found modes length:\", len(final_freqs))\n",
    "    #print(\"Final frequencies:\", final_freqs)\n",
    "    #save to csv\n",
    "    output_table.remove_column('phase change for quartile split')\n",
    "\n",
    "    output_table.add_column( ([kicID, ] * len(final_freqs)), name = 'KIC', index = 0)\n",
    "    print(output_table)\n",
    "\n",
    "    if save:\n",
    "\n",
    "        print(\"find_modes_in_star() saving results for\", kicID)\n",
    "        \n",
    "        if inject:\n",
    "            ascii.write(\n",
    "            data,\n",
    "            kicID + '_injected_stats' + '.csv',\n",
    "            overwrite=True,\n",
    "            format=\"csv\",\n",
    "            formats={\n",
    "                \"Freqs\": \"{:.7f}\",\n",
    "                \"Freq in region A\": \"{:.7f}\",\n",
    "                #\"Sharp\": \"{:.7e}\",\n",
    "                \"Delta chi2\": \"{:.7e}\",\n",
    "                #\"Change of phase(2)\": \"{:.7e}\",\n",
    "                #\"Change of lnA(2)\": \"{:.7e}\",\n",
    "                #\"Sigma lnA(4)\": \"{:.7e}\",\n",
    "                \"Sigma phi(4)\": \"{:.7e}\",\n",
    "                \"Sigma phi(jack)\" : \"{:.7e}\"\n",
    "            }\n",
    "            )\n",
    "        else:\n",
    "            ascii.write(\n",
    "            output_table,\n",
    "            kicID + '_random_stats' + '.csv',\n",
    "            overwrite=True,\n",
    "            format=\"csv\",\n",
    "            formats={\n",
    "                \"frequency\": \"{:.7f}\",\n",
    "                \"region\": \"{}\",\n",
    "                \"delta chi-squared\": \"{:.7e}\",\n",
    "                \"frequency in region A\": \"{:.7f}\",\n",
    "                \"phase uncertainty jackknife\" : \"{:.7e}\",\n",
    "                \"phase uncertainty split\": \"{:.7e}\",\n",
    "                \"phase change for A-B split\": \"{:.7e}\",\n",
    "            }\n",
    "            )\n",
    "            \n",
    "\n",
    "            #magic numbers\n",
    "\n",
    "            #for peak finding function\n",
    "                #f_avoid = 3.5 / 372.5\n",
    "                #def get_filtered_peaks(num_of_peaks, xs, ys, median_window = None, median_factor = 10.)\n",
    "                #median_factor = \n",
    "                #median_window = 21\n",
    "            \n",
    "            \n",
    "            #sampling times characterizing (not magic number)\n",
    "            # if sampling_time > 0.9 * lc_exptime:\n",
    "            #     exptime = lc_exptime\n",
    "            # if sampling_time < 1.1 * sc_exptime:\n",
    "            #     exptime = sc_exptime\n",
    "\n",
    "            #finding folding frequency, the refined frequency and its region function\n",
    "            # small, tiny = 20 * delta_f, 0.25 * delta_f #magic\n",
    "            # fc_candidates = np.arange(fc_guess - small, fc_guess + small, tiny), these are folding freuqnecy candidates\n",
    "            #fine_freqsA = np.arange(A[i] - 5 * f_min, A[i] + 5 * f_min, 0.2 * f_min), the are the chi square min frequency candidates\n",
    "            \n",
    "\n",
    "            #running median\n",
    "            #RunningMedian_power = RunningMedian(power_mini, 31)\n",
    "\n",
    "\n",
    "            #thresholds to determine if qualified frequency\n",
    "            #chi2_threshold = 100\n",
    "            #phase_uncertainty_threshold = 0.1\n",
    "\n",
    "            #maxpeaks = 100\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    print(f\"find_modes_in_star() took {time.time() - start} seconds for star {kicID}\")\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import csv\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Process an integer argument.\")\n",
    "    parser.add_argument(\"number\", type=int, help=\"An integer input\")\n",
    "    args = parser.parse_args()\n",
    "    print(f\"You entered: {args.number}\")\n",
    "\n",
    "    with open('KICids.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  #this skips the header\n",
    "        kicz = list(reader)\n",
    "\n",
    "    for row in kicz:\n",
    "        row[0] = int(str(int(row[0]))) \n",
    "\n",
    "    rando_kics = random.sample(kicz, args.number)\n",
    "    for star in rando_kics:\n",
    "        find_modes_in_star(star[0], True, True, max_peaks = 100)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
